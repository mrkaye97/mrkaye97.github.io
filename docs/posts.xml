<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Matt Kaye</title>
<link>https://www.matthewrkaye.com/posts.html</link>
<atom:link href="https://www.matthewrkaye.com/posts.xml" rel="self" type="application/rss+xml"/>
<description>Matt Kaye&#39;s personal website</description>
<generator>quarto-1.2.335</generator>
<lastBuildDate>Thu, 09 Mar 2023 05:00:00 GMT</lastBuildDate>
<item>
  <title>On AUC-ROC</title>
  <dc:creator>Matt Kaye</dc:creator>
  <link>https://www.matthewrkaye.com/posts/2023-03-09-on-auc-roc/index.html</link>
  <description><![CDATA[ 



<p><strong>AUC</strong> goes by many names: AUC, AUC-ROC, ROC-AUC, the area under the curve, and so on. It’s an extremely important metric for evaluating machine learning models and it’s an uber-popular data science interview question. It’s also, at least in my experience, the single most commonly misunderstood metric in data science.</p>
<p>I’ve heard several common misunderstandings or flat-out falsehoods from people in all kinds of roles discussing AUC. The biggest offenses tend to come from overcomplicating the topic. It’s easy to see the <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic">Wikipedia page for the ROC curve</a> and be confused, intimidated, or some combination of the two. ROC builds off of other fundamental data science concepts – the true and false positives rates of a classifier – so it’s certainly not a good place to <em>start</em> learning about metrics for evaluating the performance of models.</p>
<p>The most common cause for confusion about AUC seems to come from the plot of the <em>ROC</em> curve, and nothing particularly special about AUC itself. Generally, I’ll hear AUC explained as being the area under the ROC curve, and that it’s all about testing how well your model balances false positives and false negatives. That’s all well and good, but it doesn’t give someone new to AUC any intuition about what AUC <em>actually</em> means in practice. For instance, let’s imagine we’re trying to predict the chance that a student is accepted at Carleton College – a quite common problem at CollegeVine! How does saying “AUC tells me about how my model is balancing false negatives and false positives” tell me anything about how well my model is doing at predicting that student’s chances?</p>
<p>The main issue I have with this factual-yet-unhelpful explanation of AUC is just that: While it may be true, it doesn’t get to the point. And even worse, it’s sometimes used as a crutch: A fallback answer when someone feels stuck when asked how to interpret AUC in real, practical terms.</p>
<p>So in this post, I’ll focus on just one thing, then: Answering the question above about how to interpret AUC.</p>
<section id="what-is-auc" class="level2">
<h2 class="anchored" data-anchor-id="what-is-auc">What is AUC?</h2>
<p>As I mentioned, it’s usually not helpful to try to explain AUC to someone by telling them that it’s just the area under the ROC curve, or that it’s a metric you can use for predicting <em>probabilities</em> as opposed to predicting <em>classes</em>, or that it’s a metric trying to balance false positives and false negatives. None of those things get to the crux of the problem.</p>
<p>So what <em>is</em> AUC, then? It’s pretty simple: Let’s imagine a model <img src="https://latex.codecogs.com/png.latex?M"> being evaluated on data <img src="https://latex.codecogs.com/png.latex?X"> where <img src="https://latex.codecogs.com/png.latex?X"> contains some instances of the true class and some instances of the false class. The AUC of <img src="https://latex.codecogs.com/png.latex?M"> on <img src="https://latex.codecogs.com/png.latex?X"> is the probability that given a random item from <img src="https://latex.codecogs.com/png.latex?X"> belonging to the <em>true</em> class (<img src="https://latex.codecogs.com/png.latex?T">) and another random item from <img src="https://latex.codecogs.com/png.latex?X"> belonging to the <em>false</em> class (<img src="https://latex.codecogs.com/png.latex?F">), that the model predicts that the probability of <img src="https://latex.codecogs.com/png.latex?T"> being true (belonging to the true class) is higher than the probability of <img src="https://latex.codecogs.com/png.latex?F"> being true (belonging to the true class).</p>
<p>Let’s go back to the example about Carleton admissions, and let’s imagine that we have a model that gives a probability of admission to Carleton given some information about a student. If I give the model one random <em>accepted</em> student and one random <em>rejected</em> student, the AUC of the model is the probability that the accepted student had a higher chance of acceptance (as estimated by the model) than the rejected student did.</p>
<p>For more on this, I’d refer everyone to <a href="https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc">this fantastic blog post</a> by the team at Google, which does a great job at explaining further and/or better.</p>
</section>
<section id="a-simple-implementation" class="level2">
<h2 class="anchored" data-anchor-id="a-simple-implementation">A Simple Implementation</h2>
<p>The easiest way to convey this idea might be to show a simple implementation of AUC. Below is some R code.</p>
<p>First, let’s start by writing a function to do exactly what’s described above. Again, here’s the algorithm given some evaluation data:</p>
<ol type="1">
<li>Choose a random item from the <code>true</code> class.</li>
<li>Choose a random item from the <code>false</code> class.</li>
<li>Make a prediction on each of the two items.</li>
<li>If the predicted probability for the actually true item is greater than the predicted probability for the actually false item, return true. Otherwise, return false. If they’re equal, flip a coin.</li>
<li>Repeat 1-4 many times, and calculate the proportion of the time your model guessed correctly. This is your AUC.</li>
</ol>
<p>Now, let’s write this in R with a little help from some vectorization.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="fu" style="color: #4758AB;">library</span>(rlang)</span>
<span id="cb1-2"><span class="fu" style="color: #4758AB;">library</span>(dplyr)</span>
<span id="cb1-3"><span class="fu" style="color: #4758AB;">library</span>(tibble)</span>
<span id="cb1-4"></span>
<span id="cb1-5"><span class="do" style="color: #5E5E5E;
font-style: italic;">## Our AUC implementation</span></span>
<span id="cb1-6"><span class="do" style="color: #5E5E5E;
font-style: italic;">## In this implementation, we take a data frame containing a "truth" (i.e. whether</span></span>
<span id="cb1-7"><span class="do" style="color: #5E5E5E;
font-style: italic;">## the example is _actually_ in either the true class or the false class)</span></span>
<span id="cb1-8"><span class="do" style="color: #5E5E5E;
font-style: italic;">## and an "estimate" (our predicted probability).</span></span>
<span id="cb1-9"><span class="do" style="color: #5E5E5E;
font-style: italic;">## This implementation is in line with how {{yardstick}} implements all of its metrics</span></span>
<span id="cb1-10">interpretable_auc <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="cf" style="color: #003B4F;">function</span>(data, N, <span class="at" style="color: #657422;">truth_col =</span> <span class="st" style="color: #20794D;">"truth"</span>, <span class="at" style="color: #657422;">estimate_col =</span> <span class="st" style="color: #20794D;">"estimate"</span>) {</span>
<span id="cb1-11">  </span>
<span id="cb1-12">  <span class="do" style="color: #5E5E5E;
font-style: italic;">## First, subset the data down to just trues and just falses, separately</span></span>
<span id="cb1-13">  trues <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">filter</span>(data, .data[[truth_col]] <span class="sc" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb1-14">  falses <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">filter</span>(data, .data[[truth_col]] <span class="sc" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb1-15">  </span>
<span id="cb1-16">  <span class="do" style="color: #5E5E5E;
font-style: italic;">## Sample the predicted probabilities for N `true` examples, with replacement</span></span>
<span id="cb1-17">  random_trues <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">sample</span>(trues[[estimate_col]], <span class="at" style="color: #657422;">size =</span> N, <span class="at" style="color: #657422;">replace =</span> <span class="cn" style="color: #8f5902;">TRUE</span>)</span>
<span id="cb1-18">  </span>
<span id="cb1-19">  <span class="do" style="color: #5E5E5E;
font-style: italic;">## Do the same for N `false` examples</span></span>
<span id="cb1-20">  random_falses <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">sample</span>(falses[[estimate_col]], <span class="at" style="color: #657422;">size =</span> N, <span class="at" style="color: #657422;">replace =</span> <span class="cn" style="color: #8f5902;">TRUE</span>)</span>
<span id="cb1-21"></span>
<span id="cb1-22">  <span class="do" style="color: #5E5E5E;
font-style: italic;">## If the predicted probability for the actually true</span></span>
<span id="cb1-23">  <span class="do" style="color: #5E5E5E;
font-style: italic;">##  item is greater than that of the actually false item,</span></span>
<span id="cb1-24">  <span class="do" style="color: #5E5E5E;
font-style: italic;">##  return `true`. </span></span>
<span id="cb1-25">  <span class="do" style="color: #5E5E5E;
font-style: italic;">## If the two are equal, flip a coin.</span></span>
<span id="cb1-26">  <span class="do" style="color: #5E5E5E;
font-style: italic;">## Otherwise, return false.</span></span>
<span id="cb1-27">  true_wins <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">ifelse</span>(</span>
<span id="cb1-28">    random_trues <span class="sc" style="color: #5E5E5E;">==</span> random_falses,</span>
<span id="cb1-29">    <span class="fu" style="color: #4758AB;">runif</span>(N) <span class="sc" style="color: #5E5E5E;">&gt;</span> <span class="fl" style="color: #AD0000;">0.50</span>,</span>
<span id="cb1-30">    random_trues <span class="sc" style="color: #5E5E5E;">&gt;</span> random_falses</span>
<span id="cb1-31">  )</span>
<span id="cb1-32">  </span>
<span id="cb1-33">  <span class="do" style="color: #5E5E5E;
font-style: italic;">## Compute the percentage of the time our model was "right"</span></span>
<span id="cb1-34">  <span class="fu" style="color: #4758AB;">mean</span>(true_wins)</span>
<span id="cb1-35">}</span></code></pre></div>
</div>
<p>Next, we can test our simple implementation against <code>yardstick</code> on some real data. For the sake of demonstration, I just used the built-in <code>mtcars</code> data. Here’s how the data looks:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><span class="fu" style="color: #4758AB;">library</span>(knitr)</span>
<span id="cb2-2"><span class="fu" style="color: #4758AB;">library</span>(kableExtra)</span>
<span id="cb2-3"></span>
<span id="cb2-4"><span class="do" style="color: #5E5E5E;
font-style: italic;">## Doing a little data wrangling</span></span>
<span id="cb2-5">data <span class="ot" style="color: #003B4F;">&lt;-</span> mtcars <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb2-6">  <span class="fu" style="color: #4758AB;">transmute</span>(</span>
<span id="cb2-7">    <span class="at" style="color: #657422;">vs =</span> <span class="fu" style="color: #4758AB;">as.factor</span>(vs),</span>
<span id="cb2-8">    mpg,</span>
<span id="cb2-9">    cyl</span>
<span id="cb2-10">  ) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb2-11">  <span class="fu" style="color: #4758AB;">as_tibble</span>()</span>
<span id="cb2-12"></span>
<span id="cb2-13">data <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb2-14">  <span class="fu" style="color: #4758AB;">slice_sample</span>(<span class="at" style="color: #657422;">n =</span> <span class="dv" style="color: #AD0000;">6</span>) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb2-15">  <span class="fu" style="color: #4758AB;">kable</span>(<span class="st" style="color: #20794D;">"html"</span>, <span class="at" style="color: #657422;">caption =</span> <span class="st" style="color: #20794D;">'Six rows of our training data'</span>) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb2-16">  <span class="fu" style="color: #4758AB;">kable_styling</span>(<span class="at" style="color: #657422;">position =</span> <span class="st" style="color: #20794D;">"center"</span>, <span class="at" style="color: #657422;">full_width =</span> <span class="cn" style="color: #8f5902;">TRUE</span>)</span></code></pre></div>
<div class="cell-output-display">

<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>Six rows of our training data</caption>
 <thead>
  <tr>
   <th style="text-align:left;"> vs </th>
   <th style="text-align:right;"> mpg </th>
   <th style="text-align:right;"> cyl </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> 1 </td>
   <td style="text-align:right;"> 18.1 </td>
   <td style="text-align:right;"> 6 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 1 </td>
   <td style="text-align:right;"> 19.2 </td>
   <td style="text-align:right;"> 6 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 1 </td>
   <td style="text-align:right;"> 33.9 </td>
   <td style="text-align:right;"> 4 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 0 </td>
   <td style="text-align:right;"> 15.8 </td>
   <td style="text-align:right;"> 8 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 0 </td>
   <td style="text-align:right;"> 21.0 </td>
   <td style="text-align:right;"> 6 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 0 </td>
   <td style="text-align:right;"> 15.0 </td>
   <td style="text-align:right;"> 8 </td>
  </tr>
</tbody>
</table>

</div>
</div>
<p>Now, let’s fit a few logistic regression models to the data to see how our AUC implementation compares to the <code>yardstick</code> one.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><span class="fu" style="color: #4758AB;">library</span>(purrr)</span>
<span id="cb3-2"><span class="fu" style="color: #4758AB;">library</span>(yardstick)</span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="do" style="color: #5E5E5E;
font-style: italic;">## Simplest model -- Just an intercept. AUC should be 50%</span></span>
<span id="cb3-5">model1 <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">glm</span>(vs <span class="sc" style="color: #5E5E5E;">~</span> <span class="dv" style="color: #AD0000;">1</span>, <span class="at" style="color: #657422;">data =</span> data, <span class="at" style="color: #657422;">family =</span> binomial)</span>
<span id="cb3-6"></span>
<span id="cb3-7"><span class="do" style="color: #5E5E5E;
font-style: italic;">## Adding another predictor</span></span>
<span id="cb3-8">model2 <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">glm</span>(vs <span class="sc" style="color: #5E5E5E;">~</span> mpg, <span class="at" style="color: #657422;">data =</span> data, <span class="at" style="color: #657422;">family =</span> binomial)</span>
<span id="cb3-9"></span>
<span id="cb3-10"><span class="do" style="color: #5E5E5E;
font-style: italic;">## And another</span></span>
<span id="cb3-11">model3 <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">glm</span>(vs <span class="sc" style="color: #5E5E5E;">~</span> mpg <span class="sc" style="color: #5E5E5E;">+</span> cyl, <span class="at" style="color: #657422;">data =</span> data, <span class="at" style="color: #657422;">family =</span> binomial)</span>
<span id="cb3-12"></span>
<span id="cb3-13"><span class="do" style="color: #5E5E5E;
font-style: italic;">## Make predictions for all three models</span></span>
<span id="cb3-14">preds <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">tibble</span>(</span>
<span id="cb3-15">  <span class="at" style="color: #657422;">truth =</span> data<span class="sc" style="color: #5E5E5E;">$</span>vs,</span>
<span id="cb3-16">  <span class="at" style="color: #657422;">m1 =</span> <span class="fu" style="color: #4758AB;">predict</span>(model1, <span class="at" style="color: #657422;">type =</span> <span class="st" style="color: #20794D;">"response"</span>),</span>
<span id="cb3-17">  <span class="at" style="color: #657422;">m2 =</span> <span class="fu" style="color: #4758AB;">predict</span>(model2, <span class="at" style="color: #657422;">type =</span> <span class="st" style="color: #20794D;">"response"</span>),</span>
<span id="cb3-18">  <span class="at" style="color: #657422;">m3 =</span> <span class="fu" style="color: #4758AB;">predict</span>(model3, <span class="at" style="color: #657422;">type =</span> <span class="st" style="color: #20794D;">"response"</span>)</span>
<span id="cb3-19">)</span>
<span id="cb3-20"></span>
<span id="cb3-21"><span class="do" style="color: #5E5E5E;
font-style: italic;">## For each model, compute AUC with both methods: Yardstick (library) and "homemade"</span></span>
<span id="cb3-22"><span class="fu" style="color: #4758AB;">map_dfr</span>(</span>
<span id="cb3-23">  <span class="fu" style="color: #4758AB;">c</span>(<span class="st" style="color: #20794D;">"m1"</span>, <span class="st" style="color: #20794D;">"m2"</span>, <span class="st" style="color: #20794D;">"m3"</span>),</span>
<span id="cb3-24">  <span class="sc" style="color: #5E5E5E;">~</span> {</span>
<span id="cb3-25">    yardstick <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">roc_auc</span>(preds, <span class="at" style="color: #657422;">truth =</span> truth, <span class="at" style="color: #657422;">estimate =</span> <span class="sc" style="color: #5E5E5E;">!!</span>.x, <span class="at" style="color: #657422;">event_level =</span> <span class="st" style="color: #20794D;">"second"</span>)<span class="sc" style="color: #5E5E5E;">$</span>.estimate</span>
<span id="cb3-26">    homemade <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">interpretable_auc</span>(preds, <span class="at" style="color: #657422;">N =</span> <span class="dv" style="color: #AD0000;">100000</span>, <span class="at" style="color: #657422;">truth_col =</span> <span class="st" style="color: #20794D;">"truth"</span>, <span class="at" style="color: #657422;">estimate_col =</span> .x)</span>
<span id="cb3-27">    <span class="fu" style="color: #4758AB;">tibble</span>(</span>
<span id="cb3-28">      <span class="at" style="color: #657422;">model =</span> .x,</span>
<span id="cb3-29">      <span class="at" style="color: #657422;">yardstick =</span> <span class="fu" style="color: #4758AB;">round</span>(yardstick, <span class="at" style="color: #657422;">digits =</span> <span class="dv" style="color: #AD0000;">2</span>),</span>
<span id="cb3-30">      <span class="at" style="color: #657422;">homemade =</span> <span class="fu" style="color: #4758AB;">round</span>(homemade, <span class="at" style="color: #657422;">digits =</span> <span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb3-31">    )</span>
<span id="cb3-32">  }</span>
<span id="cb3-33">) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb3-34">  <span class="fu" style="color: #4758AB;">kable</span>(<span class="st" style="color: #20794D;">"html"</span>, <span class="at" style="color: #657422;">caption =</span> <span class="st" style="color: #20794D;">'Yardstick vs. Our Implementation'</span>) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb3-35">  <span class="fu" style="color: #4758AB;">kable_styling</span>(<span class="at" style="color: #657422;">position =</span> <span class="st" style="color: #20794D;">"center"</span>, <span class="at" style="color: #657422;">full_width =</span> <span class="cn" style="color: #8f5902;">TRUE</span>)</span></code></pre></div>
<div class="cell-output-display">

<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>Yardstick vs. Our Implementation</caption>
 <thead>
  <tr>
   <th style="text-align:left;"> model </th>
   <th style="text-align:right;"> yardstick </th>
   <th style="text-align:right;"> homemade </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> m1 </td>
   <td style="text-align:right;"> 0.50 </td>
   <td style="text-align:right;"> 0.50 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> m2 </td>
   <td style="text-align:right;"> 0.91 </td>
   <td style="text-align:right;"> 0.91 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> m3 </td>
   <td style="text-align:right;"> 0.95 </td>
   <td style="text-align:right;"> 0.95 </td>
  </tr>
</tbody>
</table>

</div>
</div>
<p>As we’ve seen here, AUC actually shouldn’t be all that much of a cause for confusion! The way I like to frame it is this: The AUC of your model is how good your model is at making even-odds bets. If I give your model two options and ask it to pick which one it thinks is more likely, a “better” model (by AUC standards) will be better at identifying the true class more often.</p>
<p>In real terms, that’s a meaningful, good thing. If we’re trying to predict the probability of a cancer patient having cancer, it’s important that our model can distinguish between people with cancer and people without it when given one person from each class. If it couldn’t - meaning the model was either randomly guessing or doing worse than random - the AUC would be 50% (or below 50%, in the worse-than-random disaster scenario).</p>
</section>
<section id="additional-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="additional-thoughts">Additional Thoughts</h2>
<p>I also often hear the misconception that AUC is sensitive to things like class imbalance. This means that if the true class makes up a disproportionately large (or small) proportion of the evaluation data, that can skew the AUC. But based on the intuition we just built before, that’s of course not true. The key thing to remember is that the model is given one true and one false example. In choosing those, it doesn’t matter if the true class only makes up 0.005% of all of the examples in the evaluation data: AUC is only evaluating the model on its ability to determine <em>which</em> of the two is the true class.</p>
<p>However, there is one thing related to class imbalance, and just sample size in general, that <em>would</em> affect AUC, which is the raw number of examples of each class in the evaluation data. If, for instance, you had only a single instance of the <code>true</code> class in the evaluation set, then the AUC of the model is entirely determined by how good the predictions of the model are on that single example. For instance, if we have a single <code>true</code> class and the model predicts a 100% probability of it being true, then, assuming the predictions for all of the other examples in the evaluation set are <em>not</em> 100%, the AUC of the model as evaluated on that data is 100%. This isn’t necessarily because the model is “good” in any sense, but just because the model is over-indexing to a single good prediction in the evaluation set. In practice though, this AUC estimate wouldn’t generalize. As we got more data, the predictions for all the true classes would certainly not all be 100%, so the AUC of the model would go down over time.</p>
<p>Fortunately, there’s an easy fix for this problem. AUCs are a point estimate, but we could also estimate a margin of error or a confidence interval for our AUC. For a situation where we only have a single instance of the true class in the evaluation set, the margin of error for our AUC would be very wide.</p>
</section>
<section id="wrapping-up" class="level2">
<h2 class="anchored" data-anchor-id="wrapping-up">Wrapping Up</h2>
<p>Hopefully this post helped give a better intuition for what AUC actually is! A couple of major takeaways:</p>
<ol type="1">
<li>AUC doesn’t need to be this super complicated thing about trading off between false positives and negatives and trying many different classification thresholds and such. In my opinion, it’s much simpler to just think about it as the likelihood of a guess that your model makes between two choices being correct.</li>
<li>AUC isn’t affected by class imbalances.</li>
</ol>


</section>

 ]]></description>
  <category>data science</category>
  <guid>https://www.matthewrkaye.com/posts/2023-03-09-on-auc-roc/index.html</guid>
  <pubDate>Thu, 09 Mar 2023 05:00:00 GMT</pubDate>
</item>
<item>
  <title>Exploring the Tail Behavior of ESPN’s Win Probability Model</title>
  <dc:creator>Matt Kaye</dc:creator>
  <link>https://www.matthewrkaye.com/posts/2023-01-09-exploring-the-tail-behavior-of-espn-s-win-probability-model/index.html</link>
  <description><![CDATA[ 



<p>It’s College Football Playoff season, which means I’ve been watching a lot of games lately. And I find myself complaining pretty often about how badly calibrated I think ESPN’s win probability model is. In particular, I’ve noted a bunch of examples – or at least enough for it to feel like a bunch – of games where ESPN’s model gives a team a win probability that feels way <em>too</em> extreme in a situation where they’re clearly winning. I’m not talking about giving a team an 80% chance when they should have a 60% chance. The cases I’ve been curious about are something more like teams getting a 99.7% chance of winning when, at least in my opinion, they should be getting something more like a 98% chance.</p>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<blockquote class="blockquote">
<p>For classification problems like predicting win probabilities, model <em>calibration</em> is, at the highest level, the answer to the question “When my model says that Michigan has a 62% chance to win, do they actually end up winning about 62% of the time?” A well-calibrated model will have relatively low error over the long run. As we get more and more data, we’d expect that the amount of error in our calibration numbers would go down, and hopefully the predicted probabilities start to converge to the actual win probabilities as the games play out. For more on calibration, check out <a href="https://projects.fivethirtyeight.com/checking-our-work/">this cool FiveThirtyEight post</a>.</p>
</blockquote>
<p>You might be reading this thinking that the difference (both in absolute terms and ratio terms) between 60 and 80 percent is way bigger than the difference between, say, 98 and 99.7. And you’d be right. But I’d encourage you to think about it like this: The team that’s the <em>underdog</em> in the latter case has either a 2% chance (the first case) or a 0.3% chance (the second case). If you’re applying the same ratio of win probabilities back of the napkin math, that increase feels a lot bigger.</p>
<blockquote class="blockquote">
<p>For the statistically inclined folks in the back, the “right” way to do this is just to use odds ratios, which would show that going from 98% to 99.7% is a massive magnitude odds (or log-odds) increase.</p>
</blockquote>
<p>So in a nutshell, what I’ve been curious about is the <em>tail behavior</em> of the ESPN model – I’m trying to answer the question of how ESPN’s model does at predicting events we know are unlikely. How often, for instance, does a team that ESPN gives a 0.5% mid-game chance of winning actually end up winning? My suspicion, based on my anecdotal evidence from watching games and complaining over the years, has been that the model is badly calibrated in the tails. I’ve been on the record arguing that ESPN’s model gives win probabilities greater than 99% way too often, and can usually be heard saying things like “Well, they’re almost definitely going to win. But 99%? I’m not sure…”</p>
<p>So then, to the question. I looked into a couple of things: 1. How well-calibrated is their model in general? 2. When ESPN gives a team a very high chance of winning (&gt;98%), how often do they actually win? 3. Does the model perform better or worse for ranked teams?</p>
</section>
<section id="calibration" class="level2">
<h2 class="anchored" data-anchor-id="calibration"><strong>Calibration</strong></h2>
<p>First, how well-calibrated is the model in general? I usually like to look at calibration plots to evaluate models, similar to the ones in the FiveThirtyEight post above.</p>
<p>This first plot is the overall calibration of the model at kickoff time. What we’re looking for are the points to roughly lie along the dashed line, which is the line <code>y = x</code>.</p>
<p align="center">
<img src="https://www.matthewrkaye.com/posts/2023-01-09-exploring-the-tail-behavior-of-espn-s-win-probability-model/https:/raw.githubusercontent.com/mrkaye97/espn-cfb-win-prob/master/plots/calibration/kickoff/all.svg" class="img-fluid" style="width:85.0%">
</p>
<p>Two main things to notice in that plot:</p>
<ol type="1">
<li>The model, on aggregate, is quite well calibrated.</li>
<li>The model looks like it’s off by a bit in the lower tail, where it appears to be predicting win probabilities that are too low. That’s a sample size issue. For instance, there were 64 games where the model gave the home team a worse than 5% chance to win, and the home team ended up winning 6.25% in those games. But generating a confidence interval for that proportion gives us a range of 1.25%-12%, which is too wide to scold the model for that mistake</li>
</ol>
<p>We can also look at the same plot, broken down by the teams playing. For instance, the following plot is broken down by whether neither team is ranked, one team is, or both teams are:</p>
<p align="center">
<img src="https://www.matthewrkaye.com/posts/2023-01-09-exploring-the-tail-behavior-of-espn-s-win-probability-model/https:/raw.githubusercontent.com/mrkaye97/espn-cfb-win-prob/master/plots/calibration/kickoff/grouped-by-num-ranked.svg" class="img-fluid" style="width:85.0%">
</p>
<p>In this case, even with relatively wide error bars, we see that the model seems to perform worse for games where both teams are ranked. And it’s pretty clearly the best in games where neither team is ranked.</p>
</section>
<section id="edge-cases" class="level2">
<h2 class="anchored" data-anchor-id="edge-cases">Edge Cases</h2>
<p>Next, I was curious about how often teams given very high chances of winning ended up doing so. Anecdotally, I’ve found myself complaining the most about games like the <a href="https://www.espn.com/college-football/game/_/gameId/401404047">Oregon - Oregon State game from 2022</a> where ESPN gives Oregon a 98.3% chance of winning when they’re up 18 with 6:53 left in the third. Of course, I’m leaning into confirmation bias. But it’s hard to not think to yourself that with more than 20 minutes of football to go, Oregon State only wins that game in a wild comeback less than two in one hundred times. I’m not sure what I’d view as a more “correct” estimate of their win probability, but seventeen in a thousand seems low to me. Maybe even thirty in a thousand (3%) would be better.</p>
<p>One note is that the 3% probability I’d probably lobby for doesn’t <em>feel</em> that different from the 1.7% that ESPN gave, but that’s an odds ratio of 1.79, which is a big difference in practice. For instance, that’s a similar odds ratio to what you’d get if you went from a 35% chance to a 50% chance, which is significant. In FiveThirtyEight world, that’s the difference between being right in the middle of the “toss-up” category vs.&nbsp;being solidly in the “lean Oregon” category.</p>
<p>So anyways, back to Oregon - Oregon State. I was curious about games like that: Games where, with more than, say, five minutes to go and one team leading by at most three scores (24 points), how often ESPN was right when they gave the leading team a better than 98% chance of winning the game.</p>
<p>As it turns out, ESPN’s model is doing pretty well in the tails on the whole. See the table below:</p>
<center>
<table class="table">
<colgroup>
<col style="width: 12%">
<col style="width: 20%">
<col style="width: 29%">
<col style="width: 29%">
<col style="width: 8%">
</colgroup>
<thead>
<tr class="header">
<th>Ranked</th>
<th>Overall Win %</th>
<th>Win % CI Lower Bound</th>
<th>Win % CI Upper Bound</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Both</td>
<td>0.54%</td>
<td>0%</td>
<td>1.63%</td>
<td>184</td>
</tr>
<tr class="even">
<td>One</td>
<td>1%</td>
<td>0.4%</td>
<td>1.7%</td>
<td>1002</td>
</tr>
<tr class="odd">
<td>Neither</td>
<td>1.07%</td>
<td>0.7%</td>
<td>1.52%</td>
<td>2427</td>
</tr>
<tr class="even">
<td>All</td>
<td>1.02%</td>
<td>0.72%</td>
<td>1.36%</td>
<td>3613</td>
</tr>
</tbody>
</table>
</center>
<p><code>Ranked</code> corresponds to how many of the teams in the game were ranked (i.e.&nbsp;“both” means “both teams were ranked”). “all” is all of the data pooled together.</p>
<p>The main takeaway from the table above is that when ESPN gives a team a &lt;2% chance of winning a game, that tends to not be a severe underestimate as I was expecting. Across the crosstabs I checked, even the high end of a 95% confidence interval for the proportion of the time that the underdog would go on to win was below the 2% threshold.</p>
</section>
<section id="wrapping-up" class="level2">
<h2 class="anchored" data-anchor-id="wrapping-up">Wrapping Up</h2>
<p>All told, I didn’t end up confirming my suspicions. At least from a cursory look through the data, ESPN’s model seems to be performing quite well in the tails. Or, at the very least, it’s not making predictions that are as ridiculous as I had thought they were. I still have my suspicions and will surely continue finding individual cases that don’t make sense to me intuitively, but after poking around a little I at least feel less concerned about the model making egregious predictions – as far as I can tell, it’s doing a pretty good job on average.</p>
</section>
<section id="future-work" class="level2">
<h2 class="anchored" data-anchor-id="future-work">Future Work</h2>
<p>A couple of other things jump out at me as being worth exploring:</p>
<ol type="1">
<li>How well did the model do vs.&nbsp;my intuitions? In games where I was on the record as thinking the win probabilities given were far too high (or low), how do <em>I</em> perform?</li>
<li>How does ESPN’s model perform by other common ML metric standards? For instance, does its AUC outperform (e.g.) Vegas? (Almost certainly not). Or how negative is the model’s Brier Skill Score when using Vegas as a baseline?</li>
<li>Does the model perform better or worse for certain teams? Maybe some teams are being consistently overrated or underrated by the model.</li>
</ol>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<p>You can find the code to reproduce this analysis <a href="https://github.com/mrkaye97/espn-cfb-win-prob">on my Github</a>.</p>


</section>

 ]]></description>
  <category>data science</category>
  <category>statistics</category>
  <category>sports analytics</category>
  <guid>https://www.matthewrkaye.com/posts/2023-01-09-exploring-the-tail-behavior-of-espn-s-win-probability-model/index.html</guid>
  <pubDate>Mon, 09 Jan 2023 05:00:00 GMT</pubDate>
  <media:content url="https://raw.githubusercontent.com/mrkaye97/espn-cfb-win-prob/master/plots/calibration/kickoff/all.svg" medium="image" type="image/svg+xml"/>
</item>
<item>
  <title>Sequential Testing</title>
  <dc:creator>Matt Kaye</dc:creator>
  <link>https://www.matthewrkaye.com/posts/2022-04-17-sequential-testing/index.html</link>
  <description><![CDATA[ 



<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>The last post proposed a solution to the multiple testing problem that often invalidates A/B test results test planning. The idea is to calculate the sample sizes you need for your test in advance, and then wait for your control and variant groups to hit those sample sizes in order to call the test. This approach is a significant methodological improvement from the “call it when it’s significant” heuristic: It prevents you from compounding the false positive rate of your test by checking on it all the time.</p>
<p>But there’s a different issue with planning the test in advance and running it until the end: It’s slow. I use “slow” to mean “slower than it needs to be,” in the sense that you will likely end up waiting too long to call a test for the variant when you could’ve made the call earlier. This waiting around is expensive – the difference between running a test for a day or two and a week or two matters <em>a lot</em> for the teams and businesses running the tests. Often, this big of a time difference can have massive effects on metrics, revenue, learnings, etc., so teams benefit from being able to call their tests faster without sacrificing any statistical rigor.</p>
<p>But how do we do that without checking in on the test all the time? Enter sequential testing.</p>
</section>
<section id="sequential-testing" class="level2">
<h2 class="anchored" data-anchor-id="sequential-testing">Sequential Testing</h2>
<p><a href="https://en.wikipedia.org/wiki/Sequential_analysis">Sequential testing</a> is a method for running experiments that allows us to evaluate the results of the test we’re running <em>along the way</em> instead of waiting to hit a pre-determined sample size. Intuitively, you might think about sequential testing like this: If early on in my test I see a massive lift in my metric, I should be able to use a lower p-value than the one I set at the start of my test to call it. It’s earlier, hence the lower p-value, but the intuitive idea is that the metric lift is so big that the p-value we’d see would be smaller than some yet undetermined p-value threshold, such that we could call the test.</p>
<p>In A/B testing world, this boils down to building checkpoints into our tests. For instance, imagine you have a test that you’re expecting to take six days to hit the final sample size that you need. If you build in three checkpoints, then you can check in on your test on day two, day four, and day six (the end of the test). On day two, if the p-value for your test is lower than the pre-determined day two p-value needed, you call the test. If it’s not, you move on to day four and repeat. Once you get to day six, if the test is still insignificant you call it for the control and end the test.</p>
<p>This gives us the best of both worlds: We have a setup where we can call the test on day two if the lift is big enough, but we can do so without inflating the false positive rate of our test. In practice, this means often being able to call tests in half, a third, a quarter, etc. of the time it’d otherwise take, which is hugely valuable for the team running the test.</p>
<blockquote class="blockquote">
<p>Statistical note: There are a number of ways to determine what p-value to use at each checkpoint when planning the test. We use the R package <code>rpact</code> for planning tests, and we plan our tests using the O’Brien-Fleming method (with alpha spending). This results in p-value thresholds that increase over time and asymptote to a value slightly less than the initial alpha you specified, depending on the number of checkpoints you build into your test. Another popular method is Pocock’s approach.</p>
</blockquote>
</section>
<section id="in-practice" class="level2">
<h2 class="anchored" data-anchor-id="in-practice">In practice</h2>
<p>So how does this work in practice? We build an internal tool that lets you plan a test given a few inputs:</p>
<ul>
<li>The alpha level (we generally use 20%, since we’re not particularly afraid of false positives and want to be able to run tests quickly)</li>
<li>The <a href="https://en.wikipedia.org/wiki/Power_of_a_test">power</a> (we generally use 95%, since we don’t want to take on many false negatives)</li>
<li>The <a href="https://support.optimizely.com/hc/en-us/articles/4410288881293-Use-minimum-detectable-effect-MDE-when-designing-an-experiment">minimum detectable effect</a></li>
<li>The baseline conversion rate</li>
<li>The expected number of users entering the funnel per day</li>
<li>The number of checkpoints to build in</li>
<li>The split of the test (is it 50/50?)</li>
<li>The number of variants (is it a true A/B test? Are there multiple variants being tested?)</li>
</ul>
<p>With those inputs, we generate a test plan which you can save, tie to a JIRA card, and send to Slack. Then all you need to do is turn on your test and wait for it to hit the first checkpoint. Once it does, you evaluate the test to get a p-value, compare it to the p-value threshold that the test plan provided at the first checkpoint, and call the test if it’s significant. If it’s not, you keep running the test up to the next checkpoint and do the same thing, and so on.</p>
</section>
<section id="the-bottom-line" class="level2">
<h2 class="anchored" data-anchor-id="the-bottom-line">The Bottom Line</h2>
<p>The main takeaway from this post is that sequential testing lets us solve two huge problems in A/B testing simultaneously: It lets us run our tests fast, and it lets us do it without sacrificing any statistical rigor. Too often, I see teams committing atrocities against statistics in the name of moving fast when they don’t need to be – using sequential designs for your A/B tests lets you control the false positive and false negative rates of your A/B tests while also allowing you to make calls on those tests as quickly as possible, which is hugely valuable.</p>
<p>And with that, we’ve concluded a four-part series on A/B testing! Hopefully you found this interesting and useful, and have taken something away that will be beneficial for your own work. Or, if I’m lucky, maybe you’re even considering overhauling how you run A/B tests.</p>


</section>

 ]]></description>
  <category>data science</category>
  <category>statistics</category>
  <guid>https://www.matthewrkaye.com/posts/2022-04-17-sequential-testing/index.html</guid>
  <pubDate>Sun, 17 Apr 2022 04:00:00 GMT</pubDate>
</item>
<item>
  <title>Calling A/B Tests</title>
  <dc:creator>Matt Kaye</dc:creator>
  <link>https://www.matthewrkaye.com/posts/2022-04-10-calling-a-b-tests/index.html</link>
  <description><![CDATA[ 



<p>In the last post, I gave a bird’s eye level overview of the mechanics of running an A/B test. But at the end, we reached a problem: We had two conversion rates – 20% and 25% – but we didn’t know if the difference between those was really big enough to make a strong claim that the blue underlines were actually performing better than the red ones in some real world sense. If you’re asking yourself whether the five percentage point difference between the two conversion rates is statistically significant, then your head’s in the right place.</p>
<p>In this post, we’ll discuss how we can determine whether our test results are statistically significant. But since statistical significance is an often confusing and nebulous topic, we’ll also explore what statistical significance even is (including what p-values are), when it’s important, and when it might not be.</p>
<section id="statistical-significance" class="level2">
<h2 class="anchored" data-anchor-id="statistical-significance">Statistical Significance</h2>
<p>Misunderstandings about statistical significance run rampant. It’s not a reach for me to say that the majority of the time I hear someone mention that something is “statistically significant” I end up rolling my eyes. But before we get into common mistakes and misunderstandings, we need to first establish what statistical significance actually is.</p>
<p>Intuitively, if something is <strong>statistically significant</strong>, it’s unlikely to have happened due to random chance. Not that scary, after all! How unlikely, though, varies wildly depending on the setting. For instance, if we’re running clinical trials to determine if a new drug is capable of curing cancer, then we want it to be <em>very</em> unlikely that we make a consequential mistake and claim that the drug works when it actually doesn’t.</p>
<p>We use p-values as the indicator of the likelihood of our result being due to random chance. In this instance, we would run our test using the number of page views and the number of conversions for each group, and depending on how we ran our test we might get a p-value of 0.43% back. What this p-value actually means is that the probability of seeing the difference in conversion rates between groups that we do (five percentage points) due to purely random chance is 0.43%. A p-value threshold of 5% is very common, so in this case we’d call the test for the variant (since 0.43% is below 5%), and we’d assert that this difference in conversion rates is <em>statistically significant</em>.</p>
</section>
<section id="eye-rolling" class="level2">
<h2 class="anchored" data-anchor-id="eye-rolling">Eye Rolling</h2>
<p>Back to my eye rolling: I often roll my eyes when someone claims that something is statistically significant for two reasons.</p>
<p>First and foremost: Something being <em>statistically significant</em> does not mean that thing is <em>significant</em>. Often we get so hung up on things being statistically significant that we forget that lifting some metric by 0.0001% isn’t <em>practically</em> significant, since it won’t make any difference in the end. If 0.0001% more people read my blog posts, what do I care? That’s something like 1 extra person every hundred years (optimistically).</p>
<p>Secondly, I often roll my eyes because of the number of choices and assumptions that need to be made along the way, many of which tend to be difficult to defend. One choice, as previously mentioned, is the p-value threshold (alpha) that you choose. In some instances, we want to be <em>very</em> confident that we’re not leaning into results that are the result of random chance, and so we might use a lower threshold. In other cases, we might be okay with taking on more risk of a false positive result in order to run our tests faster and mitigate the risk of a false <em>negative</em> (saying something does not help when it actually does).</p>
<p>Another thing that will affect the results we see is the type of test we’re running: one-tailed or two-tailed. Often, online calculators like <a href="https://www.evanmiller.org/ab-testing/chi-squared.html">this one</a> will use two-tailed tests by default because they’re more conservative. But in my opinion, using a two-tailed test doesn’t actually make any sense. Here’s why: A two-tailed test checks if the conversion rates of the variant and the control are <em>not equal</em>, which means that we can get a statistically significant result if the variant is significantly <em>worse</em> than the control, in addition to if it’s significantly <em>better</em>. But in A/B testing, we’re only going to call a test for the variant when it’s significantly better, so why do we care about the case where it’s worse? We want to test the hypothesis that the variant is significantly better than the control, not that it’s not equal, and that’s what a one-tailed test does. If you use two-tailed tests, it’ll be harder to get significant results without any real benefits.</p>
<blockquote class="blockquote">
<p>Yet another consideration is how the statistical test was actually conducted. For instance, if you use a Chi-square test with Yates’s continuity correction (the default in R, although a little controversial among statisticians), you’ll end up with higher (more conservative) p-values than if you don’t correct, which is why the p-value I just reported is higher than the one you’d get from most online calculators that don’t use the correction.</p>
</blockquote>
<p>Finally, and most importantly, is that the mechanics of running the test actually affect the chance that you are reporting a false positive result. For example, if you were to run the test described in the past few posts and calculate the p-values every time a new user visited the page and call the test for the variant the first time it were significant, you’d have just blown up the chances of a false positive result.</p>
</section>
<section id="a-common-mistake" class="level2">
<h2 class="anchored" data-anchor-id="a-common-mistake">A Common Mistake</h2>
<p>The most common mistake I see that’s made by people running A/B tests is using the “call it when it’s significant” heuristic. As I mentioned before, checking in on your test often and calling it for the variant the first time you get a significant p-value is a huge problem because the false positive rate of your test compounds the more you check on it. The reason for this is a statistical concept called <a href="https://en.wikipedia.org/wiki/Multiple_comparisons_problem">multiple testing</a>, and there’s <a href="https://xkcd.com/882/">an XKCD comic</a> about it!</p>
<p>So we want to avoid checking the test all the time, but this raises another problem: If we can’t check our test all the time, how do we know when to call it? And this is where test planning comes in. There are a number of online test planners (which generally make shoddy assumptions, like that you’re running a two-tailed test when you should be running a one-tailed one instead) like <a href="https://www.evanmiller.org/ab-testing/sample-size.html">this one</a> that take a few parameters and tell you how long to run your test for. And these planners are great! The idea is that if you can plan your test in advance, given that you know your baseline conversion rate and can specify how big of a lift you’re shooting for, then all you have to do is wait until you hit the sample size number that the calculator gives you back. Once you hit it, you check in on your test, run your p-value calculation, and call the test.</p>
<p>So, problem solved, right? Well, not quite. Because while we’ve solved the multiple testing problem where we blow up our false positive rate by checking the test all the time, now we have a new issue: We have to wait until we hit some (potentially big) sample size before we can call our test, and that’s problematic for teams that want to iterate quickly.</p>
<p>The next post in this series is the punch line. It’ll discuss sequential testing, which is the methodology that makes up the guts of how we run A/B tests at CollegeVine. Sequential testing solves the problem of needing to wait until you hit a final sample size to call your test without making any sacrifices on the rigor front, which means you can call your tests quickly and reliably.</p>


</section>

 ]]></description>
  <category>data science</category>
  <category>statistics</category>
  <category>a/b testing</category>
  <guid>https://www.matthewrkaye.com/posts/2022-04-10-calling-a-b-tests/index.html</guid>
  <pubDate>Sun, 10 Apr 2022 04:00:00 GMT</pubDate>
</item>
<item>
  <title>Running A/B Tests</title>
  <dc:creator>Matt Kaye</dc:creator>
  <link>https://www.matthewrkaye.com/posts/2022-04-10-running-a-b-tests/index.html</link>
  <description><![CDATA[ 



<p>This is the second post in a series on A/B testing. In <a href="https://mrkaye97.github.io/blog/post/2022-03-25-a-b-testing-a-primer/">the last post</a>, I gave a high-level overview of what A/B testing is and why we might do it. This post will go a few steps farther. I’ll discuss <em>how</em> an A/B test is run, what we’re looking for along the way, and what happens when we call it one way or the other. This will set us up for the next post, which will discuss the mechanics of A/B testing.</p>
<section id="how-can-i-run-an-ab-test" class="level2">
<h2 class="anchored" data-anchor-id="how-can-i-run-an-ab-test">How Can I Run An A/B Test?</h2>
<p>In the last post, I laid out a hypothetical A/B test where I was considering changing the underline color for links on my blog from red to blue. As a refresher: Blue was the variant (the new proposed color) and red was the control (the current state of the world). We were testing to see if a blue underline would cause significantly more users to click the links to my blog posts. “But,” you ask, “how does the test actually <em>happen</em>?” That’s a great question! But first, a disclaimer: I’m not an engineer, so I can only give a bird’s eye view of how we do it at CollegeVine. I’m sure there are many other solutions used by other companies.</p>
<p>At CV, we use a tool called <a href="https://launchdarkly.com/">LaunchDarkly</a> for running A/B tests. Essentially, LaunchDarkly lets us set up “feature flags” and show the version of the code that’s “behind” them to only certain users. For example, you might imagine you were rolling out a risky new change, and wanted to QA it first. One way we’ve done this kind of thing at CV is to put the risky change behind a feature flag, and then roll it out to our own team. Then, our team can QA and if anything looks off we can either fix the issues or revert the changes before rolling out to external users.</p>
<p>A/B testing with LD works similarly. Instead of only showing a new version of the code to internal users, we use a feature flag that shows each version of the code to a certain proportion of users, at random. The idea is to use the feature flag in LD to randomly sample users of our site into either the control group or the variant group. Then we track metrics over time to see if the variant is outperforming the control group.</p>
</section>
<section id="my-experiment-is-running.-now-what" class="level2">
<h2 class="anchored" data-anchor-id="my-experiment-is-running.-now-what">My Experiment Is Running. Now What?</h2>
<p>Back to our hypothetical experiment on my blog. Now, half of users are seeing red-underlined links, and half are seeing blue underlines, at random. So now, we need a way to track the conversion rate of those links. In step a whole bunch of business intelligence (BI) tools, and other tools that brand themselves as being tools for all different flavors of analytics. At CV, we use a tool called <a href="https://heap.io/">Heap</a> for user analytics (including A/B testing).</p>
<p>Let’s imagine that my blog were wired up to Heap, and tracking page views on my landing page and clicks of the links on that page to individual posts behind the scenes. In Heap, we could visualize the conversion rate from the landing page to any post in a funnel or in a table, where the conversion rate between the two is the proportion of users who hit the landing page that end up clicking one of the links (“converting”) to a post. We could also view these numbers in a table, where we’d have one cell that has the total number of sessions on the landing page and another cell with the number of sessions on the posts, and the conversion rate is the latter divided by the former (roughly).</p>
<p>Since we have our feature flag set up to track which users are being placed in each group, we can also group by that “property” in Heap, which lets us separate our analysis into the control and the variant. This means that we can compare the conversion rates for the red underline and the blue underline, which is exactly what we’re trying to do! Generally, we’ll set up a Heap dashboard with the funnel we’re interested in so we can track out metrics over time.</p>
</section>
<section id="interpreting-the-metrics" class="level2">
<h2 class="anchored" data-anchor-id="interpreting-the-metrics">Interpreting the Metrics</h2>
<p>Now that the funnel is set up, you’re watching results stream in. Let’s imagine that at some point in time, each group has 1000 users (i.e.&nbsp;1000 users have seen the variant and another 1000 have seen the control), and 250 users in the variant group converted while only 200 in the control group did. From there, we can calculate our conversion rates as 25% (variant) and 20% (control). And for the purposes of keeping this post simple, let’s assume that lift is big enough for us (by some definition of “big enough”, which we’ll get to in a later post). In that case, we call our test for the variant. In practice, this means we route all traffic to the variant instead of splitting it 50/50, and then we can remove the feature flag from our code and boom! We now have some cool blue underlines for the links on the blog.</p>
<p>But back to the lift being big enough: In practice, is knowing that the variant is performing 25% better than the control enough to call the test for the variant? Making this call in a rigorous, informed way is what the rest of the posts in this series will discuss.</p>


</section>

 ]]></description>
  <category>data science</category>
  <category>statistics</category>
  <category>a/b testing</category>
  <guid>https://www.matthewrkaye.com/posts/2022-04-10-running-a-b-tests/index.html</guid>
  <pubDate>Sat, 09 Apr 2022 04:00:00 GMT</pubDate>
</item>
<item>
  <title>A/B Testing: A Primer</title>
  <dc:creator>Matt Kaye</dc:creator>
  <link>https://www.matthewrkaye.com/posts/2022-03-25-a-b-testing-a-primer/index.html</link>
  <description><![CDATA[ 



<p>This is the first post in a series I’m planning on writing on A/B testing. In this post, I’ll lay out a top-level overview of what A/B testing is and why companies do it. In future posts, I plan on diving into some common pitfalls, bad habits, and anti-patterns I’ve seen, and the systems we’ve put in place to mitigate them and allow our team to run statistically rigorous, fast A/B tests to make informed product decisions as quickly as possible.</p>
<p>At work, we generally try to keep documents like this written at a high level: The objective is for them to be understandable and useful for general audience. That will be the case here too, for the most part.</p>
<blockquote class="blockquote">
<p>In these posts, I’ll use callout boxes like this (in addition to <code>Appendix</code> sections) to walk through technical details. If you’re not interested in the weeds, feel free to skip these sections entirely!</p>
</blockquote>
<section id="whats-an-ab-test" class="level2">
<h2 class="anchored" data-anchor-id="whats-an-ab-test">What’s an A/B Test?</h2>
<p>So, what is an A/B test, anyways? It’s probably easiest to explain with an example:</p>
<p>Let’s imagine that I had been tracking the click rate on my blog posts over time. It’s pretty terrible – let’s say that the rate that someone clicks into any particular post from the main menu page is 5%. This means that of all of the views of my blog’s main page, only 5% of those page views actually result in a click on one of my posts. Pretty miserable, right?</p>
<p>But today I’m feeling optimistic. Right now, when a user hovers over a post title, it gets underlined in red. “But wait!” I think. What would happen if I made the underline blue instead?</p>
<p>And now, I have an A/B test. In this test, the “A” group (or the “control”) is the current state of the world: The red underline. The “B” group (or the “variant” or “treatment” group) is the proposed change: The blue underline.</p>
<p>The basic idea of an A/B test is to run these two versions of my blog side-by-side, measuring the click rate in each version, and seeing which version ends up performing better. If the blue underline version – the variant – ends up increasing the click rate to my blog posts, then the conclusion is that I’d be better off permanently changing the underline to blue.</p>
</section>
<section id="why-test" class="level2">
<h2 class="anchored" data-anchor-id="why-test">Why Test?</h2>
<p>In my trivial example above, the color of the underline doesn’t seem super consequential (and it’s not). But this isn’t always the case. For instance, Facebook changed their notification icon color from blue to red once upon a time, and the rest was history. Amazon might A/B test a new model for recommending products to users, or Netflix a new model for recommending shows. A company doing lots of email marketing might A/B test different types of ways of addressing their emails (e.g.&nbsp;“Dear Matt” vs.&nbsp;“Hey Matt”), and so, so much more. Changes like these can have enormous business implications, and, as such, A/B testing makes up the backbone of so much of the tech and products we interface with every day. Companies want to maximize their conversion rates, click rates, revenues, etc. and A/B testing is one tool in their tool box for optimizing all of the metrics they care about.</p>
<p>If there’s one takeaway here, it’s this: Someone wants to make their product “better” in some sense, and to figure out whether or not a new idea of theirs is actually better than the current state of the world, they test it.</p>
<blockquote class="blockquote">
<p>In statistics world, generally A/B tests boil down to testing “conversion rates” against each other, which usually means that the tests being run are Chi-square tests of independence of the proportions of success across the two groups. If the variant is significantly better than the control, we call the test for the variant and roll it out to 100% of users. You might also use a t-test to (e.g.) test if the variant results in significantly more sessions than the control does, or you might use a time series technique like Bayesian structural time series to do pre/post testing to compare user behavior before and after a treatment was applied. For the curious, Google has published an awesome R package called CausalImpact (and an associated talk and some papers, I believe) on this.</p>
</blockquote>
</section>
<section id="up-next" class="level2">
<h2 class="anchored" data-anchor-id="up-next">Up Next…</h2>
<p>As I mentioned before, the rest of this series of posts will focus, roughly, on the following topics: 1. Okay, so we know what an A/B test is, but how do we actually <em>run</em> one? 2. What are the most common anti-patterns, pitfalls, and bad habits that I’ve seen, and why are they problematic? 3. What are we doing to correct those issues to allow our team to run fast, statistically rigorous A/B tests?</p>


</section>

 ]]></description>
  <category>data science</category>
  <category>statistics</category>
  <category>a/b testing</category>
  <guid>https://www.matthewrkaye.com/posts/2022-03-25-a-b-testing-a-primer/index.html</guid>
  <pubDate>Fri, 25 Mar 2022 04:00:00 GMT</pubDate>
</item>
<item>
  <title>Deploying MLFlow on Heroku (with Heroku Postgres, S3, and nginx for basic auth)</title>
  <dc:creator>Matt Kaye</dc:creator>
  <link>https://www.matthewrkaye.com/posts/2021-12-26-deploying-mlflow-on-heroku-with-heroku-postgres-s3-and-nginx-for-basic-auth/index.html</link>
  <description><![CDATA[ 



<p>Disclaimer: I followed <a href="https://www.mikulskibartosz.name/how-to-deploy-mlflow-on-heroku/">this guide</a> to setting up MLFlow on Heroku initially. However, there were certain aspects of it that are either outdated or do not work, so this post remedies those issues.</p>
<section id="mlflow" class="level2">
<h2 class="anchored" data-anchor-id="mlflow">MLFlow</h2>
<p><a href="https://www.mlflow.org/">MLFlow</a> is an open source tool for the entire machine learning lifecycle. It lets you create and experiment with models, write notes and descriptions, track parameters, metrics, and artifacts, and deploy to production all through an easy-to-use API and an intuitive UI. You can make calls to a running MLFlow service through the <a href="https://www.mlflow.org/docs/latest/R-api.html">R API</a>, the <a href="https://www.mlflow.org/docs/latest/python_api/index.html">Python API</a>, the <a href="https://www.mlflow.org/docs/latest/java_api/index.html">Java API</a>, or via the command line (cURL) or your favorite language by interacting with the <a href="https://www.mlflow.org/docs/latest/rest-api.html">REST API</a>.</p>
</section>
<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<p>MLFlow is surprisingly easy to set up and deploy to Heroku. There are a few steps to follow to get everything running: 1. Dockerize an MLFlow instance 2. Set up an artifact store 3. Set up a database 4. Secure the instance with basic auth</p>
</section>
<section id="prerequisites" class="level2">
<h2 class="anchored" data-anchor-id="prerequisites">Prerequisites</h2>
<p>This guide assumes you already have AWS (specifically S3) set up. It also assumes some knowledge of shell scripting, Docker, and Heroku.</p>
</section>
<section id="creating-a-heroku-app" class="level2">
<h2 class="anchored" data-anchor-id="creating-a-heroku-app">Creating a Heroku App</h2>
<p>First, let’s create a Heroku app from the CLI. For the purposes of this example, I’m going to call the app <code>my-mlflow-example</code>. You’ll need to choose your own app name.</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="ex" style="color: null;">heroku</span> create my-mlflow-example</span></code></pre></div>
<p>Next, let’s attach a Heroku Postgres instance.</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><span class="ex" style="color: null;">heroku</span> addons:create heroku-postgresql:hobby-dev <span class="at" style="color: #657422;">--app</span> my-mlflow-example</span></code></pre></div>
<p>Creating this hobby-dev Heroku Postgres instance will also automatically set the <code>DATABASE_URL</code> environment variable in your app’s configuration.</p>
<p>Next, we’ll need some other environment variables to be set. You can set your config like this:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><span class="ex" style="color: null;">heroku</span> config:set <span class="dt" style="color: #AD0000;">\</span></span>
<span id="cb3-2">  S3_URI=s3://YOUR-S3-URI <span class="dt" style="color: #AD0000;">\</span></span>
<span id="cb3-3">  AWS_SECRET_ACCESS_KEY=YOUR-SECRET <span class="dt" style="color: #AD0000;">\</span></span>
<span id="cb3-4">  AWS_ACCESS_KEY_ID=YOUR-KEY <span class="dt" style="color: #AD0000;">\</span></span>
<span id="cb3-5">  AWS_DEFAULT_REGION=YOUR-REGION <span class="dt" style="color: #AD0000;">\</span></span>
<span id="cb3-6">  MLFLOW_TRACKING_USERNAME=YOUR-USERNAME <span class="dt" style="color: #AD0000;">\</span></span>
<span id="cb3-7">  MLFLOW_TRACKING_PASSWORD=YOUR-PASSWORD <span class="dt" style="color: #AD0000;">\</span></span>
<span id="cb3-8">  <span class="at" style="color: #657422;">--app</span> my-mlflow-example</span></code></pre></div>
<p>You can repeat fewer lines of code by creating a <code>.env</code> file that looks like this:</p>
<pre class="text"><code>S3_URI=s3://YOUR-S3-URI AWS_SECRET_ACCESS_KEY=YOUR-SECRET ...</code></pre>
<p>and then using <code>heroku config:set .env --app my-mlflow-example</code>.</p>
<p>Great! At this point, your Heroku app should be all set up. Now all we need to do is create the Docker image that will run MLFlow.</p>
</section>
<section id="setup" class="level2">
<h2 class="anchored" data-anchor-id="setup">Setup</h2>
<p>First thing’s first, let’s create a folder called <code>my-mlflow-example</code> where we’ll store all the files we’ll need. I’ll do that with:</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><span class="fu" style="color: #4758AB;">mkdir</span> my-mlflow-example <span class="kw" style="color: #003B4F;">&amp;&amp;</span> <span class="bu" style="color: null;">cd</span> my-mlflow-example</span></code></pre></div>
<p>Next, let’s create a few files we’ll need:</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><span class="fu" style="color: #4758AB;">touch</span> Dockerfile run.sh requirements.txt nginx.conf_template</span></code></pre></div>
<p>You’ll also want to make your <code>run.sh</code> script executable.</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><span class="fu" style="color: #4758AB;">chmod</span> +x run.sh</span></code></pre></div>
<p>Great, now we’ve to all the files we’ll need to deploy our MLFlow instance!</p>
<section id="the-dockerfile" class="level3">
<h3 class="anchored" data-anchor-id="the-dockerfile">The <code>Dockerfile</code></h3>
<p>The <a href="https://www.docker.com/">Dockerfile</a> will contain all of the library installs and files you need to run your MLFlow instance. The Dockerfile you’ll need to write for MLFlow should look something like this:</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb8-1"><span class="ex" style="color: null;">FROM</span> continuumio/miniconda3</span>
<span id="cb8-2"></span>
<span id="cb8-3"><span class="co" style="color: #5E5E5E;">## Copy files into the image</span></span>
<span id="cb8-4"><span class="ex" style="color: null;">COPY</span> run.sh run.sh</span>
<span id="cb8-5"><span class="ex" style="color: null;">COPY</span> requirements.txt requirements.txt</span>
<span id="cb8-6"><span class="ex" style="color: null;">COPY</span> nginx.conf_template /etc/nginx/sites-available/default/nginx.conf_template</span>
<span id="cb8-7"></span>
<span id="cb8-8"><span class="co" style="color: #5E5E5E;">## Install Postgres</span></span>
<span id="cb8-9"><span class="ex" style="color: null;">RUN</span> apt-get <span class="at" style="color: #657422;">-y</span> update <span class="kw" style="color: #003B4F;">&amp;&amp;</span> <span class="dt" style="color: #AD0000;">\</span></span>
<span id="cb8-10">  <span class="ex" style="color: null;">apt-get</span> <span class="at" style="color: #657422;">-y</span> upgrade <span class="kw" style="color: #003B4F;">&amp;&amp;</span> <span class="dt" style="color: #AD0000;">\</span></span>
<span id="cb8-11">  <span class="ex" style="color: null;">apt-get</span> install <span class="at" style="color: #657422;">-y</span> postgresql</span>
<span id="cb8-12"></span>
<span id="cb8-13"><span class="co" style="color: #5E5E5E;">## Install nginx and dependencies</span></span>
<span id="cb8-14"><span class="ex" style="color: null;">RUN</span> apt-get <span class="at" style="color: #657422;">-y</span> update <span class="kw" style="color: #003B4F;">&amp;&amp;</span> <span class="dt" style="color: #AD0000;">\</span></span>
<span id="cb8-15">  <span class="ex" style="color: null;">apt-get</span> install <span class="at" style="color: #657422;">-y</span> make vim <span class="dt" style="color: #AD0000;">\</span></span>
<span id="cb8-16">  automake gcc g++ subversion <span class="dt" style="color: #AD0000;">\</span></span>
<span id="cb8-17">  musl-dev nginx gettext apache2-utils</span>
<span id="cb8-18"></span>
<span id="cb8-19"><span class="co" style="color: #5E5E5E;">## Install pip and dependencies</span></span>
<span id="cb8-20"><span class="ex" style="color: null;">RUN</span> conda install <span class="at" style="color: #657422;">-c</span> anaconda pip <span class="kw" style="color: #003B4F;">&amp;&amp;</span> <span class="dt" style="color: #AD0000;">\</span></span>
<span id="cb8-21">  <span class="ex" style="color: null;">pip</span> install <span class="at" style="color: #657422;">--upgrade</span> pip <span class="kw" style="color: #003B4F;">&amp;&amp;</span> <span class="dt" style="color: #AD0000;">\</span></span>
<span id="cb8-22">  <span class="ex" style="color: null;">pip</span> install <span class="at" style="color: #657422;">-r</span> requirements.txt <span class="kw" style="color: #003B4F;">&amp;&amp;</span> <span class="dt" style="color: #AD0000;">\</span></span>
<span id="cb8-23">  <span class="ex" style="color: null;">conda</span> update <span class="at" style="color: #657422;">-n</span> base <span class="at" style="color: #657422;">-c</span> defaults conda <span class="kw" style="color: #003B4F;">&amp;&amp;</span> <span class="dt" style="color: #AD0000;">\</span></span>
<span id="cb8-24">  <span class="ex" style="color: null;">conda</span> env list <span class="kw" style="color: #003B4F;">&amp;&amp;</span> <span class="dt" style="color: #AD0000;">\</span></span>
<span id="cb8-25">  <span class="ex" style="color: null;">pip</span> freeze list</span>
<span id="cb8-26"></span>
<span id="cb8-27"><span class="co" style="color: #5E5E5E;">## Run your `run.sh` script on container boot</span></span>
<span id="cb8-28"><span class="ex" style="color: null;">CMD</span> ./run.sh</span></code></pre></div>
</section>
<section id="the-requirements.txt-file" class="level3">
<h3 class="anchored" data-anchor-id="the-requirements.txt-file">The <code>requirements.txt</code> File</h3>
<p>Next, copy the following lines into your <code>requirements.txt</code>:</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode txt code-with-copy"><code class="sourceCode default"><span id="cb9-1">mlflow</span>
<span id="cb9-2">psycopg2-binary</span>
<span id="cb9-3">boto3</span></code></pre></div>
<p>This file will tell <code>pip</code> which libraries to install in your docker image in the <code>RUN pip install -r requirements.txt</code> line above.</p>
</section>
<section id="the-nginx-template" class="level3">
<h3 class="anchored" data-anchor-id="the-nginx-template">The <code>nginx</code> Template</h3>
<p>Next, we’ll create a template for the <code>nginx.conf</code> file that we’ll eventually use in the container for basic auth. One important issue here: This file is a <strong><em>template</em></strong> because Heroku randomly assigns a port on dyno start, which means we can’t hard code any ports for <code>nginx</code> (since we don’t know them ahead of time). Instead of hard-coding, we specify a couple of placeholders: <code>$HEROKU_PORT</code> and <code>$MLFLOW_PORT</code>. We’ll replace these with the proper ports on container startup.</p>
<p>Your <code>nginx.conf_template</code> should look like this:</p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb10-1"><span class="ex" style="color: null;">events</span> {}</span>
<span id="cb10-2"><span class="ex" style="color: null;">http</span> {</span>
<span id="cb10-3">  <span class="ex" style="color: null;">server</span> {</span>
<span id="cb10-4">        <span class="ex" style="color: null;">listen</span> <span class="va" style="color: #111111;">$HEROKU_PORT</span><span class="kw" style="color: #003B4F;">;</span></span>
<span id="cb10-5"></span>
<span id="cb10-6">        <span class="ex" style="color: null;">access_log</span> /var/log/nginx/reverse-access.log<span class="kw" style="color: #003B4F;">;</span></span>
<span id="cb10-7">        <span class="ex" style="color: null;">error_log</span> /var/log/nginx/reverse-error.log<span class="kw" style="color: #003B4F;">;</span></span>
<span id="cb10-8"></span>
<span id="cb10-9">        <span class="ex" style="color: null;">location</span> / {</span>
<span id="cb10-10">            <span class="ex" style="color: null;">auth_basic</span> <span class="st" style="color: #20794D;">"Restricted Content"</span><span class="kw" style="color: #003B4F;">;</span></span>
<span id="cb10-11">            <span class="ex" style="color: null;">auth_basic_user_file</span> /etc/nginx/.htpasswd<span class="kw" style="color: #003B4F;">;</span></span>
<span id="cb10-12"></span>
<span id="cb10-13">            <span class="ex" style="color: null;">proxy_pass</span>                          http://127.0.0.1:<span class="va" style="color: #111111;">$MLFLOW_PORT</span>/<span class="kw" style="color: #003B4F;">;</span></span>
<span id="cb10-14">            <span class="ex" style="color: null;">proxy_set_header</span> Host               <span class="va" style="color: #111111;">$host</span><span class="kw" style="color: #003B4F;">;</span></span>
<span id="cb10-15">            <span class="ex" style="color: null;">proxy_set_header</span> X-Real-IP          <span class="va" style="color: #111111;">$remote_addr</span><span class="kw" style="color: #003B4F;">;</span></span>
<span id="cb10-16">            <span class="ex" style="color: null;">proxy_set_header</span> X-Forwarded-For    <span class="va" style="color: #111111;">$proxy_add_x_forwarded_for</span><span class="kw" style="color: #003B4F;">;</span></span>
<span id="cb10-17">        <span class="er" style="color: #AD0000;">}</span></span>
<span id="cb10-18">    <span class="er" style="color: #AD0000;">}</span></span>
<span id="cb10-19"><span class="er" style="color: #AD0000;">}</span></span></code></pre></div>
</section>
<section id="run-script" class="level3">
<h3 class="anchored" data-anchor-id="run-script">Run Script</h3>
<p>Finally, let’s create a script, <code>run.sh</code>, which will run when the Heroku dyno starts.</p>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb11-1"><span class="bu" style="color: null;">export</span> <span class="va" style="color: #111111;">HEROKU_PORT</span><span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">$(</span><span class="bu" style="color: null;">echo</span> <span class="st" style="color: #20794D;">"</span><span class="va" style="color: #111111;">$PORT</span><span class="st" style="color: #20794D;">"</span><span class="va" style="color: #111111;">)</span></span>
<span id="cb11-2"><span class="bu" style="color: null;">export</span> <span class="va" style="color: #111111;">MLFLOW_PORT</span><span class="op" style="color: #5E5E5E;">=</span>5000</span>
<span id="cb11-3"></span>
<span id="cb11-4"><span class="ex" style="color: null;">envsubst</span> <span class="st" style="color: #20794D;">'$HEROKU_PORT,$MLFLOW_PORT'</span> <span class="op" style="color: #5E5E5E;">&lt;</span> /etc/nginx/sites-available/default/nginx.conf_template <span class="op" style="color: #5E5E5E;">&gt;</span> /etc/nginx/sites-available/default/nginx.conf</span>
<span id="cb11-5"></span>
<span id="cb11-6"><span class="ex" style="color: null;">htpasswd</span> <span class="at" style="color: #657422;">-bc</span> /etc/nginx/.htpasswd <span class="va" style="color: #111111;">$MLFLOW_TRACKING_USERNAME</span> <span class="va" style="color: #111111;">$MLFLOW_TRACKING_PASSWORD</span></span>
<span id="cb11-7"></span>
<span id="cb11-8"><span class="fu" style="color: #4758AB;">killall</span> nginx</span>
<span id="cb11-9"></span>
<span id="cb11-10"><span class="ex" style="color: null;">mlflow</span> ui <span class="dt" style="color: #AD0000;">\</span></span>
<span id="cb11-11">  <span class="at" style="color: #657422;">--port</span> <span class="va" style="color: #111111;">$MLFLOW_PORT</span> <span class="dt" style="color: #AD0000;">\</span></span>
<span id="cb11-12">  <span class="at" style="color: #657422;">--host</span> 127.0.0.1 <span class="dt" style="color: #AD0000;">\</span></span>
<span id="cb11-13">  <span class="at" style="color: #657422;">--backend-store-uri</span> <span class="va" style="color: #111111;">$(</span><span class="bu" style="color: null;">echo</span> <span class="st" style="color: #20794D;">"</span><span class="va" style="color: #111111;">$DATABASE_URL</span><span class="st" style="color: #20794D;">"</span> <span class="kw" style="color: #003B4F;">|</span> <span class="fu" style="color: #4758AB;">sed</span> <span class="st" style="color: #20794D;">"s/postgres/postgresql/"</span><span class="va" style="color: #111111;">)</span> <span class="dt" style="color: #AD0000;">\</span></span>
<span id="cb11-14">  <span class="at" style="color: #657422;">--default-artifact-root</span> <span class="va" style="color: #111111;">$S3_URI</span> <span class="kw" style="color: #003B4F;">&amp;</span></span>
<span id="cb11-15"></span>
<span id="cb11-16"><span class="ex" style="color: null;">nginx</span> <span class="at" style="color: #657422;">-g</span> <span class="st" style="color: #20794D;">'daemon off;'</span> <span class="at" style="color: #657422;">-c</span> /etc/nginx/sites-available/default/nginx.conf</span></code></pre></div>
<p>There are a few things happening here: 1. We set the <code>HEROKU_PORT</code> environment variable from the randomly assigned <code>PORT</code> that Heroku creates on dyno startup 2. We assign <code>MLFLOW_PORT</code> to <code>5000</code>. The chances that Heroku assigns <em>exactly</em> port <code>5000</code> are low. If you want, you can add a few more lines to first check if Heroku assigns <code>5000</code> as the port, and if it does, choose any other port instead (e.g.&nbsp;<code>1000</code>). 3. We substitute the port placeholder variables in our <code>nginx.conf_template</code> file with the actual environment variable values for the ports, so that <code>nginx</code> knows where to listen and direct traffic. 4. We create a new <code>.htpasswd</code> file from the <code>MLFLOW_TRACKING_USERNAME</code> and <code>MLFLOW_TRACKING_PASSWORD</code> environment variables that we set in the Heroku config. This file will be used by <code>nginx</code> to check inputted usernames and passwords against. 5. We start the MLFlow UI in the background, telling it to run on the <code>MLFLOW_PORT</code> variable we created, and pointing it to our Heroku Postgres instance for the backend store and our S3 bucket for artifact storage. <strong>Note: By default, Heroku Postgres provides a URL that begins with <code>postgres</code>. This is not compatible with <code>SQLAlchemy</code>, so we substitute <code>postgresql</code> (which is compatible) for <code>postgres</code>.</strong> 6. We start <code>nginx</code> for basic auth.</p>
</section>
</section>
<section id="deploying" class="level2">
<h2 class="anchored" data-anchor-id="deploying">Deploying</h2>
<p>Deployment is simple, and can be done with a few lines of <code>bash</code>:</p>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb12-1"><span class="ex" style="color: null;">heroku</span> login</span>
<span id="cb12-2"><span class="ex" style="color: null;">heroku</span> container:login</span>
<span id="cb12-3"><span class="ex" style="color: null;">heroku</span> container:push web <span class="at" style="color: #657422;">--app</span> my-mlflow-example</span>
<span id="cb12-4"><span class="ex" style="color: null;">heroku</span> container:release web <span class="at" style="color: #657422;">--app</span> my-mlflow-example</span></code></pre></div>
<p>And that’s it! Running those four lines should build your Docker image, push it to Heroku, and release it as your app. Once it releases, Heroku will boot up a dyno and you should be able to go to <code>my-mlflow-example.herokuapp.com</code> and see the MLFlow UI.</p>
</section>
<section id="using-mlflow" class="level2">
<h2 class="anchored" data-anchor-id="using-mlflow">Using MLFlow</h2>
<p>Now that your instance is deployed, you should have no problem using MLFlow for your whole ML lifecycle. For example, in R you might want to create a new experiment. You could do something like this:</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><span class="do" style="color: #5E5E5E;
font-style: italic;">## install.packages("mlflow")</span></span>
<span id="cb13-2"></span>
<span id="cb13-3"><span class="fu" style="color: #4758AB;">library</span>(mlflow)</span>
<span id="cb13-4"></span>
<span id="cb13-5"><span class="do" style="color: #5E5E5E;
font-style: italic;">## Set up some environment variables</span></span>
<span id="cb13-6"><span class="do" style="color: #5E5E5E;
font-style: italic;">## This way, your R session will know where to</span></span>
<span id="cb13-7"><span class="do" style="color: #5E5E5E;
font-style: italic;">##  look for your MLFlow instance and will have</span></span>
<span id="cb13-8"><span class="do" style="color: #5E5E5E;
font-style: italic;">##  the proper credentials set up</span></span>
<span id="cb13-9"><span class="fu" style="color: #4758AB;">Sys.setenv</span>(</span>
<span id="cb13-10">  <span class="at" style="color: #657422;">MLFLOW_TRACKING_URI =</span> <span class="st" style="color: #20794D;">"https://my-mlflow-example.herokuapp.com"</span></span>
<span id="cb13-11">  <span class="at" style="color: #657422;">MLFLOW_TRACKING_USERNAME =</span> <span class="st" style="color: #20794D;">"YOUR-USERNAME"</span>,</span>
<span id="cb13-12">  <span class="at" style="color: #657422;">MLFLOW_TRACKING_PASSWORD =</span> <span class="st" style="color: #20794D;">"YOUR-PASSWORD"</span></span>
<span id="cb13-13">)</span>
<span id="cb13-14"></span>
<span id="cb13-15"><span class="fu" style="color: #4758AB;">mlflow_create_experiment</span>(<span class="st" style="color: #20794D;">"my-first-experiment"</span>)</span></code></pre></div>
<p>And with that, you should be able to harness all of the awesome power of MLFlow for all of your ML lifecycle needs!</p>


</section>

 ]]></description>
  <category>mlops</category>
  <guid>https://www.matthewrkaye.com/posts/2021-12-26-deploying-mlflow-on-heroku-with-heroku-postgres-s3-and-nginx-for-basic-auth/index.html</guid>
  <pubDate>Sun, 26 Dec 2021 05:00:00 GMT</pubDate>
</item>
<item>
  <title>Notes on Hiring Data Analysts + Scientists</title>
  <dc:creator>Matt Kaye</dc:creator>
  <link>https://www.matthewrkaye.com/posts/2021-12-22-notes-on-hiring-data-analysts-scientists/index.html</link>
  <description><![CDATA[ 



<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>In the past four months, I’ve been involved in hiring for two new roles at <a href="https://www.collegevine.com/">CollegeVine</a>: a second data scientist, and our first data analyst. I’ve learned a lot along the way: Things that work, things that don’t, and things to ask in order to maximize the amount of signal we’re getting from our interviews. This post will sketch out our hiring process (the processes are very similar for our DS and DA roles, with slightly different questions), and I’ll add some notes about things I’ve learned along the way. It’s been a long time since I’ve written anything! I’m excited, so here goes.</p>
</section>
<section id="our-process" class="level2">
<h2 class="anchored" data-anchor-id="our-process">Our Process</h2>
<p>Our hiring process only has a few steps. We try to keep things simple and quick:</p>
<ol type="1">
<li>A phone screen with the hiring manager (30-45 minutes)</li>
<li>A technical interview with two data scientists (60-90 minutes)</li>
<li>A technical interview with two software developers (60 minutes, data science only)</li>
<li>Two cultural / behavioral interviews</li>
</ol>
<p>Since my portion of the process is the <em>data science</em> part, I’ll leave the phone screens, behavioral rounds, and system design round out of this post.</p>
</section>
<section id="the-data-science-analysis-interview" class="level2">
<h2 class="anchored" data-anchor-id="the-data-science-analysis-interview">The Data Science / Analysis Interview</h2>
<p>I’ve done a whole bunch of data science interviews from both sides of the table. Some have been better than others. Often, while on the hot seat, I’ve gotten a smorgasborg of questions that felt like they came from the first page of the first Google result for “Data science interview questions.” A handful of examples:</p>
<ul>
<li>What’s the difference between supervised and unsupervised learning?</li>
<li>What’s the difference between linear regression and logistic regression?</li>
<li>What’s a p-value?</li>
<li>How do you know when something is an outlier?</li>
</ul>
<p>And many, many more. In my view, these questions are <em>fine</em>. They ask about a relevant concept to data science and put your skills to the test. But I have two issues with them. First, they’re neither challenging nor questions that are easy to build on in terms of difficulty. Second, they’re not going to be good questions to figure out someone’s ability level.</p>
<section id="creating-challenging-questions" class="level3">
<h3 class="anchored" data-anchor-id="creating-challenging-questions">Creating Challenging Questions</h3>
<p>When I say the questions above aren’t challenging, I mean that these are the kinds of questions that someone who’s taken a single stats or machine learning class would be able to answer. This is fine if you’re trying to figure out if someone has taken one of said classes, but that isn’t our goal. We’re trying to determine your ability to succeed as a data scientist or analyst. This means that we need to know more than just your academic background: We need to know how you reason about stats and ML, and how you think in general. How do you approach a statistics problem where you haven’t seen the solution before? Can you intuit an answer and defend it?</p>
<p>As a result, we’ve designed our questions to be challenging enough that you wouldn’t have seen them in a class you took, and to build off of one another. For example, we often ask the following question:</p>
<blockquote class="blockquote">
<p>Imagine you’re looking at a distribution of the heights of men in Spain. How might you find which men are outliers?</p>
</blockquote>
<p>Sure, easy question. There are a handful of fine answers here, but we’re generally looking for something along the lines of using a <a href="https://en.wikipedia.org/wiki/Standard_score">Z-Score</a> or the <a href="https://en.wikipedia.org/wiki/Interquartile_range#:~:text=In%20descriptive%20statistics%2C%20the%20interquartile,25th%20percentiles%20of%20the%20data.">IQR</a>. Either of those shows that you’ve seen some rule of thumb in a statistics class and realize that you can apply it to this problem.</p>
<p>But then, we ask a follow-up:</p>
<blockquote class="blockquote">
<p>Now, let’s imagine you’re looking at the distribution of <em>incomes</em> of men in Spain, instead of their heights. Does your approach change at all?</p>
</blockquote>
<p>This is a question that most candidates need to think about for a little bit. At first, it seems simple. But we give you a hint: We explicitly ask if your approach to the problem would change, which is a push to think about <em>how</em> it might change. Many candidates struggle with this question, seemingly for a few reasons:</p>
<ul>
<li>They understand the hint, but don’t immediately realize why the Z-Score or the IQR approach breaks down, so they feel stuck.</li>
<li>They understand why those approaches don’t work, but it doesn’t jump out at them what they should <em>do</em> about it.</li>
</ul>
<p>These types of responses aren’t surprising to us: In statistics classes, you normally work with normally distributed data where nice properties and rules of thumb hold up, but now we have a problem: Everyone knows that incomes are skewed, and so now what do we do? Some candidates stick to their guns and insist the IQR or Z-score would still be fine. Here’s how I’d answer the question:</p>
<ul>
<li>First, I’d make a point that incomes are <a href="https://en.wikipedia.org/wiki/Skewness">right-skewed</a>. Everyone probably has this image in their head already, but it’s important.</li>
<li>Next, I’d note that the IQR / Z-score approach would break down, since the rules of thumb we use about 95% of the data (e.g.) lying within 2 standard deviations of the mean only works on a normal distribution, which incomes do not follow. This means we can’t just arbitrarly say “Oh, this person is more than 2 standard deviations from the mean, so he’s an outlier!” anymore.</li>
<li>Finally, I’d think about other approaches. One might be something fancy like an <a href="https://en.wikipedia.org/wiki/Isolation_forest">isolation forest</a>, but I think there’s a simpler approach that’d work: Since incomes are severely right skewed, we could try taking the log of the incomes to see if the logged income looks roughly normally distributed. If it does, we can fall back on our IQR or Z-score approach.</li>
</ul>
<p>The point here is to ask the candidate a question that makes them think intuitively about having to solve a real-world problem (in this case, one we face all the time) that they probably haven’t seen before, which gives us a lot of signal about their statistical foundations and intuitions.</p>
<p>We follow up this follow-up with another:</p>
<blockquote class="blockquote">
<p>Now, let’s imagine we’re looking for outliers in the heights of men again, but this time they’re from Sweden <em>and</em> Spain. Does your approach change?</p>
</blockquote>
<p>Similar question here, with no real clear, immediate answer that jumps out at most candidates. A reasonable response would be to just separate the distributions into Swedish and Spanish (since we know that Swedes are taller than Spaniards, on average), and then fall back on the Z-score or IQR approach again. Again, not a particularly challenging, in the weeds, or niche technical question by any stretch, but definitely one that lets us really get a sense for your intuitive ability.</p>
<blockquote class="blockquote">
<p><strong>TL;DR: We build questions that aren’t tricky (in the trick question sense), but should’t have an immediately obvious canned answer. These types of questions should give us a window into how you reason intuitvely about statistics and machine learning concepts at all levels of complexity.</strong></p>
</blockquote>
</section>
<section id="layering-questions" class="level3">
<h3 class="anchored" data-anchor-id="layering-questions">Layering Questions</h3>
<p>This point is a nice segue into the second issue I noted above: It’s important to build questions that have multiple layers of difficulty to them, so that if someone immediately answers your question, you don’t completely shift gears and move to a different topic. Instead, we want to keep digging, so that we can figure out just how much you know. The question I laid out above is a good example of a simple, relatively straightforward question with multiple layers.</p>
<p>Here’s another example:</p>
<blockquote class="blockquote">
<p>Imagine you’re asking people their symptoms and trying to figure out if they have COVID or not. Sometimes you’ll say someone has COVID when they don’t, and sometimes you’ll say they don’t when they do. What are these two types of mistakes called? And which one do you think is worse? Why?</p>
</blockquote>
<p>This is a question about <a href="https://en.wikipedia.org/wiki/Type_I_and_type_II_errors">Type I and Type II</a> error (also known as false positives and false negatives, respectively). Most candidates realize this right away, and then make an argument for why they think a Type II error (the false negative) is a worse mistake. Generally, the argument centers on someone who <em>is</em> infected unknowingly spreading COVID. That’s a great answer. It shows that they can reason about different types of mistakes and can make an argument for why we might want to minimize one or the other. But this isn’t a particularly challenging question.</p>
<p>We ask a follow-up:</p>
<blockquote class="blockquote">
<p>Now, let’s imagine you get some COVID test results back from the people whose symptoms you were asking about. What’s wrong with this statement: ‘If COVID tests have a 10% false negative rate and you got a COVID test and it’s negative, that means there’s a 10% chance it’s wrong and you’re actually positive.’?</p>
</blockquote>
<p>This question is a little more challenging, and it builds of the types of error we discussed in the previous question. Here, you need to realize what a <a href="https://en.wikipedia.org/wiki/False_positives_and_false_negatives">false negative</a> is, and it’s easy to get the <a href="https://en.wikipedia.org/wiki/Conditional_probability">conditioning</a> flipped. In this case, the false negative rate of the test being 10% means that the probability that you test negative <em>given that you have COVID</em> is 10%. This is <em>not</em> the same as saying that the probability that you have COVID <em>given that you test negative</em> is 10%. In the second case, the conditioning is flipped around backwards. Most candidates get hung up on this, and rightfully so. It’s a tricky question to work out without pen and paper.</p>
<p>For those that get through that question, we have another, more difficult follow-up:</p>
<blockquote class="blockquote">
<p>Okay, so you got a negative test result, but you know the false negative rate of COVID tests is 10%. Imagine you wanted to calculate the actual chance you were <em>positive</em> given that you just got your negative result. What other information would you need to do your calculation?</p>
</blockquote>
<p>For the Bayesians in the back, this question should be a slam dunk. It’s an obvious <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem">Bayes’ Rule</a> question: we’re asking you to calculate <code>p( COVID | negative test )</code>, so you can use Bayes’ Rule to find the answer. It turns out the other information you’d need to do this calculation (in addition to the false negative rate) are a true negative rate and a <a href="https://en.wikipedia.org/wiki/Prior_probability">prior</a>, and you’re golden.</p>
<p>Lastly, once a candidate successfully identified Bayes’ Rule and (hopefully) discussed priors, we’d ask them how they’d elicit this prior. There’s no “right” answer here, but there are a couple options that are better than others:</p>
<ul>
<li>Ask an expert</li>
<li>Use something relatively uninformative</li>
<li>Take an “empirical” approach and use something like the overall positive test rate</li>
</ul>
<p>Any of these answers would be totally reasonable, given that there’s a whole literature on prior elicitation.</p>
<p>And that’s one example of a multi-layer question we might ask in a data science interview. The vast majority of candidates won’t get through all the parts, and that’s totally fine! Errr, maybe “fine” isn’t actually the right word: That’s <em>the goal</em>. The point is that we’re constructing a question that lets us learn <em>a lot</em> about you: We learn how much you know about Type I / II error and how you reason about them. We learn about if you understand conditional probability and Bayes’ Rule. And we learn how you reason about prior elicitation. We also learn how you argue for decisions you make, and how you communicate complicated statistical concepts (Bayes’ Rule and Type I / II error aren’t simple). And finally, we learn something about the <em>depth</em> of your knowledge. The first part of this question you’d probably know the answer to if you’d taken an introductory statistics or ML class. The second part you’d likely see in a probability course or an inferential statistics course. The third part would also probably come up in one of those two courses, and if not, then certainly in a Bayesian statistics course. And finally, the fourth part you’d likely only see in a very advanced inferential statistics course or a Bayesian course. So not only do we see how you reason about statistics, how much you know, and how you communicate difficult concepts, we also learn something about the types of problems you’ve seen or worked on in the past, whether they be in classes or in a former job or internship. This is <em>a lot</em> of useful information.</p>
</section>
</section>
<section id="the-take-home" class="level2">
<h2 class="anchored" data-anchor-id="the-take-home">The Take Home</h2>
<p>The other piece to our interview process is a take home project. For data science, we have a take-home that you can find in our <a href="https://github.com/collegevine/ds-hiring">CollegeVine DS Hiring Github repo</a>. For data analysts, we ask them to bring in any project they’ve done in the past: Anything from a homework assignment to another company’s take home.</p>
<p>We spend about 25-30 minutes going through the take home project, and we’re looking for a few main things. For the most part, candidates are good at describing what they’ve done, so we’re generally trying to dig to figure out <em>why</em> they made the decisions they did. Can they defend them? How did they think through the pros and cons of each decision? What’s their thought process like? The idea here is that everyone in a data-related role will need to make decisions where there’s no clear “right” answer, so we want to see why you chose to make a pie chart instead of a box plot, or chose to use <a href="https://en.wikipedia.org/wiki/XGBoost">XGBoost</a> instead of logistic regression. Can you talk me through the pros and cons of each option?</p>
<p>In the data science take home we give, there are also some tricks we’re trying to test the candidates out on. In an effort to not give away our whole bag of tricks, I invite everyone to give the exercise a shot! I’d even be happy to take a look through your projects to see what you come up with. The short of it is that there are some issues in the data that, if you don’t notice them and do something to fix them, will end up ruining the predictions your model produces. We don’t expect anyone to catch all of these issues in the short amount of time we ask them to spend on the problem, but we hope that they’ll be thoughtful about how they’d solve them once we point them out in the interview.</p>
<p>Finally, there’s one elephant in the room here that’s important to address: Many people feel negatively about take homes. So do we – they tend to be long and unnecessarily complicated, and often feel like a waste of the candidate’s time. In our view, though, the take home is necessary for one main reason: It lets you familiarize yourself with a data science problem beforehand, so that when you get to the interview we can hit the ground running. In a sense, we’re giving you the rules of the game in advance so we can start playing right away. This lets us avoid any confusion or annoying ambiguity with regards to the types of problems were asking about, and to entirely avoid requiring candidates to reason through questions about entirely hypothetical problems that they’ve never seen before. For these reasons, and also because there’s historically been lots of signal that we’ve gotten from how candidates respond to our questions about the project they bring in, we’ve decided to stick with the take home. In addition, we don’t screen out any candidates on the basis of their take home. We don’t ask them to be submitted in advance, so every candidate who does a take home gets an interview.</p>
</section>
<section id="wrapping-up" class="level2">
<h2 class="anchored" data-anchor-id="wrapping-up">Wrapping Up</h2>
<p>In a nutshell, that’s our whole data scientific technical interview! We discuss a take home you bring in, and then we talk through some miscellaneous statistics and machine learning questions like the ones we discussed above. In general, we’re not looking for any specific expertise or knowledge – we’re a start up, after all. Instead, we’re testing candidates to see how they reason about problems that are similar to the ones they’ll work on at CollegeVine, and how they explain the ins and outs of different possible solutions to those problems. We’re looking at their intuitions about statistics and machine learning, their ability to think on their feet when faced with questions they don’t immediately know the answer to, and their curiosity and creativity when it comes to solving challenging questions. At the end of the day, it’s these traits, not any hyper-specific technical knowledge, that’ll make for a great CV data team member.</p>


</section>

 ]]></description>
  <category>data science</category>
  <category>hiring</category>
  <guid>https://www.matthewrkaye.com/posts/2021-12-22-notes-on-hiring-data-analysts-scientists/index.html</guid>
  <pubDate>Wed, 22 Dec 2021 05:00:00 GMT</pubDate>
</item>
<item>
  <title>Working With Your Fitbit Data in R</title>
  <dc:creator>Matt Kaye</dc:creator>
  <link>https://www.matthewrkaye.com/posts/2021-06-08-working-with-your-fitbit-data-in-r/index.html</link>
  <description><![CDATA[ 



<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p><code>fitbitr 0.1.0</code> is now available on CRAN! You can install it with</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="fu" style="color: #4758AB;">install.packages</span>(<span class="st" style="color: #20794D;">"fitbitr"</span>)</span></code></pre></div>
<p>or you can get the latest dev version with</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><span class="do" style="color: #5E5E5E;
font-style: italic;">## install.packages("devtools")</span></span>
<span id="cb2-2">devtools<span class="sc" style="color: #5E5E5E;">::</span><span class="fu" style="color: #4758AB;">install_github</span>(<span class="st" style="color: #20794D;">"mrkaye97/fitbitr"</span>)</span></code></pre></div>
<p><code>fitbitr</code> makes it easy to pull your Fitbit data into R and use it for whatever interests you: personal projects, visualization, medical purposes, etc.</p>
<p>This post shows how you might use <code>fitbitr</code> to pull and visualize some of your data.</p>
</section>
<section id="sleep" class="level2">
<h2 class="anchored" data-anchor-id="sleep">Sleep</h2>
<p>First, you should either generate a new token with <code>generate_token()</code> or load a cached token with <code>load_cached_token()</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><span class="fu" style="color: #4758AB;">library</span>(fitbitr)</span>
<span id="cb3-2"><span class="fu" style="color: #4758AB;">library</span>(lubridate)</span>
<span id="cb3-3"><span class="fu" style="color: #4758AB;">library</span>(tidyverse)</span>
<span id="cb3-4"></span>
<span id="cb3-5"><span class="do" style="color: #5E5E5E;
font-style: italic;">## Dates to use throughout post</span></span>
<span id="cb3-6">start <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">as_date</span>(<span class="st" style="color: #20794D;">"2020-01-01"</span>)</span>
<span id="cb3-7">end <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">as_date</span>(<span class="st" style="color: #20794D;">"2021-10-18"</span>)</span>
<span id="cb3-8"></span>
<span id="cb3-9"><span class="co" style="color: #5E5E5E;"># load_cached_token(".httr-oauth")</span></span></code></pre></div>
</div>
<p>And then you can start pulling your data!</p>
<div class="cell" data-layout-align="center" data-hash="index_cache/html/unnamed-chunk-4_d869f5e763a1b9067febc3686cee8cec">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1">sleep <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">sleep_summary</span>(</span>
<span id="cb4-2">  <span class="at" style="color: #657422;">start_date =</span> end <span class="sc" style="color: #5E5E5E;">-</span> <span class="fu" style="color: #4758AB;">months</span>(<span class="dv" style="color: #AD0000;">3</span>),</span>
<span id="cb4-3">  <span class="at" style="color: #657422;">end_date =</span> end</span>
<span id="cb4-4">)</span>
<span id="cb4-5"></span>
<span id="cb4-6">sleep <span class="sc" style="color: #5E5E5E;">%&gt;%</span> </span>
<span id="cb4-7">  <span class="fu" style="color: #4758AB;">head</span>()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 × 11
       log_id date       start_time          end_time            durat…¹ effic…²
        &lt;dbl&gt; &lt;date&gt;     &lt;dttm&gt;              &lt;dttm&gt;                &lt;int&gt;   &lt;int&gt;
1 33020894524 2021-07-18 2021-07-17 23:39:00 2021-07-18 07:58:00  2.99e7      98
2 33033378227 2021-07-19 2021-07-18 22:17:30 2021-07-19 07:43:30  3.40e7      95
3 33043882288 2021-07-20 2021-07-19 22:57:00 2021-07-20 06:38:30  2.77e7      96
4 33060458937 2021-07-21 2021-07-20 23:24:30 2021-07-21 06:34:00  2.57e7      97
5 33075070785 2021-07-22 2021-07-21 22:21:00 2021-07-22 06:55:30  3.08e7      90
6 33087900074 2021-07-23 2021-07-22 23:36:30 2021-07-23 07:08:30  2.71e7      95
# … with 5 more variables: minutes_to_fall_asleep &lt;int&gt;, minutes_asleep &lt;int&gt;,
#   minutes_awake &lt;int&gt;, minutes_after_wakeup &lt;int&gt;, time_in_bed &lt;int&gt;, and
#   abbreviated variable names ¹​duration, ²​efficiency</code></pre>
</div>
</div>
<p>Once you’ve loaded some data, you can visualize it!</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><span class="fu" style="color: #4758AB;">library</span>(zoo)</span>
<span id="cb6-2"><span class="fu" style="color: #4758AB;">library</span>(scales)</span>
<span id="cb6-3"><span class="fu" style="color: #4758AB;">library</span>(ggthemes)</span>
<span id="cb6-4"></span>
<span id="cb6-5">sleep <span class="ot" style="color: #003B4F;">&lt;-</span> sleep <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb6-6">  <span class="fu" style="color: #4758AB;">mutate</span>(</span>
<span id="cb6-7">   <span class="at" style="color: #657422;">date =</span> <span class="fu" style="color: #4758AB;">as_date</span>(date),</span>
<span id="cb6-8">   <span class="at" style="color: #657422;">start_time =</span> <span class="fu" style="color: #4758AB;">as_datetime</span>(start_time),</span>
<span id="cb6-9">   <span class="at" style="color: #657422;">end_time =</span> <span class="fu" style="color: #4758AB;">as_datetime</span>(end_time),</span>
<span id="cb6-10">   <span class="at" style="color: #657422;">sh =</span> <span class="fu" style="color: #4758AB;">ifelse</span>(<span class="fu" style="color: #4758AB;">hour</span>(start_time) <span class="sc" style="color: #5E5E5E;">&lt;</span> <span class="dv" style="color: #AD0000;">8</span>, <span class="fu" style="color: #4758AB;">hour</span>(start_time) <span class="sc" style="color: #5E5E5E;">+</span> <span class="dv" style="color: #AD0000;">24</span>, <span class="fu" style="color: #4758AB;">hour</span>(start_time)), <span class="co" style="color: #5E5E5E;">#create numeric times</span></span>
<span id="cb6-11">   <span class="at" style="color: #657422;">sm =</span> <span class="fu" style="color: #4758AB;">minute</span>(start_time),</span>
<span id="cb6-12">   <span class="at" style="color: #657422;">st =</span> sh <span class="sc" style="color: #5E5E5E;">+</span> sm<span class="sc" style="color: #5E5E5E;">/</span><span class="dv" style="color: #AD0000;">60</span>,</span>
<span id="cb6-13">   <span class="at" style="color: #657422;">eh =</span> <span class="fu" style="color: #4758AB;">hour</span>(end_time),</span>
<span id="cb6-14">   <span class="at" style="color: #657422;">em =</span> <span class="fu" style="color: #4758AB;">minute</span>(end_time),</span>
<span id="cb6-15">   <span class="at" style="color: #657422;">et =</span> eh <span class="sc" style="color: #5E5E5E;">+</span> em<span class="sc" style="color: #5E5E5E;">/</span><span class="dv" style="color: #AD0000;">60</span>,</span>
<span id="cb6-16">   <span class="at" style="color: #657422;">mst =</span> <span class="fu" style="color: #4758AB;">rollmean</span>(st, <span class="dv" style="color: #AD0000;">7</span>, <span class="at" style="color: #657422;">fill =</span> <span class="cn" style="color: #8f5902;">NA</span>), <span class="co" style="color: #5E5E5E;">#create moving averages</span></span>
<span id="cb6-17">   <span class="at" style="color: #657422;">met =</span> <span class="fu" style="color: #4758AB;">rollmean</span>(et, <span class="dv" style="color: #AD0000;">7</span>, <span class="at" style="color: #657422;">fill =</span> <span class="cn" style="color: #8f5902;">NA</span>),</span>
<span id="cb6-18">   <span class="at" style="color: #657422;">year =</span> <span class="fu" style="color: #4758AB;">year</span>(start_time)</span>
<span id="cb6-19">)</span>
<span id="cb6-20"></span>
<span id="cb6-21">sleep <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb6-22">    <span class="fu" style="color: #4758AB;">ggplot</span>(<span class="fu" style="color: #4758AB;">aes</span>(<span class="at" style="color: #657422;">x =</span> date))<span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb6-23">    <span class="fu" style="color: #4758AB;">geom_line</span>(<span class="fu" style="color: #4758AB;">aes</span>(<span class="at" style="color: #657422;">y =</span> et), <span class="at" style="color: #657422;">color =</span> <span class="st" style="color: #20794D;">'coral'</span>, <span class="at" style="color: #657422;">alpha =</span> .<span class="dv" style="color: #AD0000;">3</span>, <span class="at" style="color: #657422;">na.rm =</span> T)<span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb6-24">    <span class="fu" style="color: #4758AB;">geom_line</span>(<span class="fu" style="color: #4758AB;">aes</span>(<span class="at" style="color: #657422;">y =</span> st), <span class="at" style="color: #657422;">color =</span> <span class="st" style="color: #20794D;">'dodgerblue'</span>, <span class="at" style="color: #657422;">alpha =</span> .<span class="dv" style="color: #AD0000;">3</span>, <span class="at" style="color: #657422;">na.rm =</span> T)<span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb6-25">    <span class="fu" style="color: #4758AB;">geom_line</span>(<span class="fu" style="color: #4758AB;">aes</span>(<span class="at" style="color: #657422;">y =</span> met), <span class="at" style="color: #657422;">color =</span> <span class="st" style="color: #20794D;">'coral'</span>, <span class="at" style="color: #657422;">na.rm=</span>T)<span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb6-26">    <span class="fu" style="color: #4758AB;">geom_line</span>(<span class="fu" style="color: #4758AB;">aes</span>(<span class="at" style="color: #657422;">y =</span> mst), <span class="at" style="color: #657422;">color =</span> <span class="st" style="color: #20794D;">'dodgerblue'</span>, <span class="at" style="color: #657422;">na.rm=</span>T)<span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb6-27">    <span class="fu" style="color: #4758AB;">scale_y_continuous</span>(<span class="at" style="color: #657422;">breaks =</span> <span class="fu" style="color: #4758AB;">seq</span>(<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">30</span>, <span class="dv" style="color: #AD0000;">2</span>),</span>
<span id="cb6-28">                       <span class="at" style="color: #657422;">labels =</span> <span class="fu" style="color: #4758AB;">trans_format</span>(<span class="cf" style="color: #003B4F;">function</span>(x) <span class="fu" style="color: #4758AB;">ifelse</span>(x <span class="sc" style="color: #5E5E5E;">&gt;</span> <span class="dv" style="color: #AD0000;">23</span>, x <span class="sc" style="color: #5E5E5E;">-</span> <span class="dv" style="color: #AD0000;">24</span>, x), </span>
<span id="cb6-29">                                             <span class="at" style="color: #657422;">format =</span> scales<span class="sc" style="color: #5E5E5E;">::</span><span class="fu" style="color: #4758AB;">comma_format</span>(<span class="at" style="color: #657422;">suffix =</span> <span class="st" style="color: #20794D;">":00"</span>, <span class="at" style="color: #657422;">accuracy =</span> <span class="dv" style="color: #AD0000;">1</span>))</span>
<span id="cb6-30">    )<span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb6-31">    <span class="fu" style="color: #4758AB;">labs</span>(<span class="at" style="color: #657422;">x =</span> <span class="st" style="color: #20794D;">"Date"</span>,</span>
<span id="cb6-32">         <span class="at" style="color: #657422;">y =</span> <span class="st" style="color: #20794D;">'Time'</span>)<span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb6-33">    <span class="fu" style="color: #4758AB;">theme_fivethirtyeight</span>()<span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb6-34">  <span class="fu" style="color: #4758AB;">scale_x_date</span>(<span class="at" style="color: #657422;">date_breaks =</span> <span class="st" style="color: #20794D;">'1 month'</span>, <span class="at" style="color: #657422;">date_labels =</span> <span class="st" style="color: #20794D;">'%b'</span>, <span class="at" style="color: #657422;">expand =</span> <span class="fu" style="color: #4758AB;">c</span>(<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">0</span>))<span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb6-35">  <span class="fu" style="color: #4758AB;">facet_grid</span>(. <span class="sc" style="color: #5E5E5E;">~</span> year, <span class="at" style="color: #657422;">space =</span> <span class="st" style="color: #20794D;">'free'</span>, <span class="at" style="color: #657422;">scales =</span> <span class="st" style="color: #20794D;">'free_x'</span>, <span class="at" style="color: #657422;">switch =</span> <span class="st" style="color: #20794D;">'x'</span>) <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb6-36">  <span class="fu" style="color: #4758AB;">theme</span>(<span class="at" style="color: #657422;">panel.spacing.x =</span> <span class="fu" style="color: #4758AB;">unit</span>(<span class="dv" style="color: #AD0000;">0</span>,<span class="st" style="color: #20794D;">"line"</span>), </span>
<span id="cb6-37">        <span class="at" style="color: #657422;">strip.placement =</span> <span class="st" style="color: #20794D;">"outside"</span>)</span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.matthewrkaye.com/posts/2021-06-08-working-with-your-fitbit-data-in-r/static/rmarkdown-libsunnamed-chunk-5-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>This bit of code makes a nicely formatted plot of the times you went to sleep and woke up over the past three months. You can also use <code>fitbitr</code> to expand the time window with a little help from <code>purrr</code> (the Fitbit API rate limits you, so you can’t request data for infinitely long windows in a single request).</p>
<div class="cell" data-layout-align="center" data-hash="index_cache/html/unnamed-chunk-6_af35efd52163eeefe06857cbd3a33893">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><span class="do" style="color: #5E5E5E;
font-style: italic;">## Pull three months of data</span></span>
<span id="cb7-2">sleep <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">map_dfr</span>(</span>
<span id="cb7-3">  <span class="dv" style="color: #AD0000;">3</span><span class="sc" style="color: #5E5E5E;">:</span><span class="dv" style="color: #AD0000;">0</span>,</span>
<span id="cb7-4">  <span class="sc" style="color: #5E5E5E;">~</span> <span class="fu" style="color: #4758AB;">sleep_summary</span>(</span>
<span id="cb7-5">    end <span class="sc" style="color: #5E5E5E;">-</span> <span class="fu" style="color: #4758AB;">months</span>(.x), </span>
<span id="cb7-6">    end <span class="sc" style="color: #5E5E5E;">-</span> <span class="fu" style="color: #4758AB;">months</span>(.x) <span class="sc" style="color: #5E5E5E;">+</span> <span class="fu" style="color: #4758AB;">months</span>(<span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb7-7">  )</span>
<span id="cb7-8">)</span></code></pre></div>
</div>
<p>After pulling the data, we can use the same code again to visualize it.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1">sleep <span class="ot" style="color: #003B4F;">&lt;-</span> sleep <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb8-2">  <span class="fu" style="color: #4758AB;">mutate</span>(</span>
<span id="cb8-3">   <span class="at" style="color: #657422;">date =</span> <span class="fu" style="color: #4758AB;">as_date</span>(date),</span>
<span id="cb8-4">   <span class="at" style="color: #657422;">start_time =</span> <span class="fu" style="color: #4758AB;">as_datetime</span>(start_time),</span>
<span id="cb8-5">   <span class="at" style="color: #657422;">end_time =</span> <span class="fu" style="color: #4758AB;">as_datetime</span>(end_time),</span>
<span id="cb8-6">   <span class="at" style="color: #657422;">sh =</span> <span class="fu" style="color: #4758AB;">ifelse</span>(<span class="fu" style="color: #4758AB;">hour</span>(start_time) <span class="sc" style="color: #5E5E5E;">&lt;</span> <span class="dv" style="color: #AD0000;">8</span>, <span class="fu" style="color: #4758AB;">hour</span>(start_time) <span class="sc" style="color: #5E5E5E;">+</span> <span class="dv" style="color: #AD0000;">24</span>, <span class="fu" style="color: #4758AB;">hour</span>(start_time)), <span class="co" style="color: #5E5E5E;">#create numeric times</span></span>
<span id="cb8-7">   <span class="at" style="color: #657422;">sm =</span> <span class="fu" style="color: #4758AB;">minute</span>(start_time),</span>
<span id="cb8-8">   <span class="at" style="color: #657422;">st =</span> sh <span class="sc" style="color: #5E5E5E;">+</span> sm<span class="sc" style="color: #5E5E5E;">/</span><span class="dv" style="color: #AD0000;">60</span>,</span>
<span id="cb8-9">   <span class="at" style="color: #657422;">eh =</span> <span class="fu" style="color: #4758AB;">hour</span>(end_time),</span>
<span id="cb8-10">   <span class="at" style="color: #657422;">em =</span> <span class="fu" style="color: #4758AB;">minute</span>(end_time),</span>
<span id="cb8-11">   <span class="at" style="color: #657422;">et =</span> eh <span class="sc" style="color: #5E5E5E;">+</span> em<span class="sc" style="color: #5E5E5E;">/</span><span class="dv" style="color: #AD0000;">60</span>,</span>
<span id="cb8-12">   <span class="at" style="color: #657422;">mst =</span> <span class="fu" style="color: #4758AB;">rollmean</span>(st, <span class="dv" style="color: #AD0000;">7</span>, <span class="at" style="color: #657422;">fill =</span> <span class="cn" style="color: #8f5902;">NA</span>), <span class="co" style="color: #5E5E5E;">#create moving averages</span></span>
<span id="cb8-13">   <span class="at" style="color: #657422;">met =</span> <span class="fu" style="color: #4758AB;">rollmean</span>(et, <span class="dv" style="color: #AD0000;">7</span>, <span class="at" style="color: #657422;">fill =</span> <span class="cn" style="color: #8f5902;">NA</span>),</span>
<span id="cb8-14">   <span class="at" style="color: #657422;">year =</span> <span class="fu" style="color: #4758AB;">year</span>(start_time)</span>
<span id="cb8-15">) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb8-16">  <span class="fu" style="color: #4758AB;">distinct</span>()</span>
<span id="cb8-17"></span>
<span id="cb8-18">sleep <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb8-19">    <span class="fu" style="color: #4758AB;">ggplot</span>(<span class="fu" style="color: #4758AB;">aes</span>(<span class="at" style="color: #657422;">x =</span> date))<span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb8-20">    <span class="fu" style="color: #4758AB;">geom_line</span>(<span class="fu" style="color: #4758AB;">aes</span>(<span class="at" style="color: #657422;">y =</span> et), <span class="at" style="color: #657422;">color =</span> <span class="st" style="color: #20794D;">'coral'</span>, <span class="at" style="color: #657422;">alpha =</span> .<span class="dv" style="color: #AD0000;">3</span>, <span class="at" style="color: #657422;">na.rm =</span> T)<span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb8-21">    <span class="fu" style="color: #4758AB;">geom_line</span>(<span class="fu" style="color: #4758AB;">aes</span>(<span class="at" style="color: #657422;">y =</span> st), <span class="at" style="color: #657422;">color =</span> <span class="st" style="color: #20794D;">'dodgerblue'</span>, <span class="at" style="color: #657422;">alpha =</span> .<span class="dv" style="color: #AD0000;">3</span>, <span class="at" style="color: #657422;">na.rm =</span> T)<span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb8-22">    <span class="fu" style="color: #4758AB;">geom_line</span>(<span class="fu" style="color: #4758AB;">aes</span>(<span class="at" style="color: #657422;">y =</span> met), <span class="at" style="color: #657422;">color =</span> <span class="st" style="color: #20794D;">'coral'</span>, <span class="at" style="color: #657422;">na.rm=</span>T)<span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb8-23">    <span class="fu" style="color: #4758AB;">geom_line</span>(<span class="fu" style="color: #4758AB;">aes</span>(<span class="at" style="color: #657422;">y =</span> mst), <span class="at" style="color: #657422;">color =</span> <span class="st" style="color: #20794D;">'dodgerblue'</span>, <span class="at" style="color: #657422;">na.rm=</span>T)<span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb8-24">    <span class="fu" style="color: #4758AB;">scale_y_continuous</span>(<span class="at" style="color: #657422;">breaks =</span> <span class="fu" style="color: #4758AB;">seq</span>(<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">30</span>, <span class="dv" style="color: #AD0000;">2</span>),</span>
<span id="cb8-25">                       <span class="at" style="color: #657422;">labels =</span> <span class="fu" style="color: #4758AB;">trans_format</span>(<span class="cf" style="color: #003B4F;">function</span>(x) <span class="fu" style="color: #4758AB;">ifelse</span>(x <span class="sc" style="color: #5E5E5E;">&gt;</span> <span class="dv" style="color: #AD0000;">23</span>, x <span class="sc" style="color: #5E5E5E;">-</span> <span class="dv" style="color: #AD0000;">24</span>, x), </span>
<span id="cb8-26">                                             <span class="at" style="color: #657422;">format =</span> scales<span class="sc" style="color: #5E5E5E;">::</span><span class="fu" style="color: #4758AB;">comma_format</span>(<span class="at" style="color: #657422;">suffix =</span> <span class="st" style="color: #20794D;">":00"</span>, <span class="at" style="color: #657422;">accuracy =</span> <span class="dv" style="color: #AD0000;">1</span>))</span>
<span id="cb8-27">    )<span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb8-28">    <span class="fu" style="color: #4758AB;">labs</span>(<span class="at" style="color: #657422;">x =</span> <span class="st" style="color: #20794D;">"Date"</span>,</span>
<span id="cb8-29">         <span class="at" style="color: #657422;">y =</span> <span class="st" style="color: #20794D;">'Time'</span>)<span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb8-30">    <span class="fu" style="color: #4758AB;">theme_fivethirtyeight</span>()<span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb8-31">  <span class="fu" style="color: #4758AB;">scale_x_date</span>(<span class="at" style="color: #657422;">date_breaks =</span> <span class="st" style="color: #20794D;">'1 month'</span>, <span class="at" style="color: #657422;">date_labels =</span> <span class="st" style="color: #20794D;">'%b'</span>, <span class="at" style="color: #657422;">expand =</span> <span class="fu" style="color: #4758AB;">c</span>(<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">0</span>))<span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb8-32">  <span class="fu" style="color: #4758AB;">facet_grid</span>(. <span class="sc" style="color: #5E5E5E;">~</span> year, <span class="at" style="color: #657422;">space =</span> <span class="st" style="color: #20794D;">'free'</span>, <span class="at" style="color: #657422;">scales =</span> <span class="st" style="color: #20794D;">'free_x'</span>, <span class="at" style="color: #657422;">switch =</span> <span class="st" style="color: #20794D;">'x'</span>) <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb8-33">  <span class="fu" style="color: #4758AB;">theme</span>(<span class="at" style="color: #657422;">panel.spacing.x =</span> <span class="fu" style="color: #4758AB;">unit</span>(<span class="dv" style="color: #AD0000;">0</span>,<span class="st" style="color: #20794D;">"line"</span>), </span>
<span id="cb8-34">        <span class="at" style="color: #657422;">strip.placement =</span> <span class="st" style="color: #20794D;">"outside"</span>)</span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.matthewrkaye.com/posts/2021-06-08-working-with-your-fitbit-data-in-r/static/rmarkdown-libsunnamed-chunk-7-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="heart-rate-and-steps" class="level2">
<h2 class="anchored" data-anchor-id="heart-rate-and-steps">Heart Rate and Steps</h2>
<p>You can also pull your heart rate data with <code>fitbitr</code>. Maybe we’re curious about seeing how the number of minutes spent in the “fat burn,” “cardio,” and “peak” zones correlates with the number of steps taken that day. Let’s find out!</p>
<div class="cell" data-layout-align="center" data-hash="index_cache/html/unnamed-chunk-8_df41135438270860bd7e0fd1091a4efa">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1">hr <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">map_dfr</span>(</span>
<span id="cb9-2">  <span class="dv" style="color: #AD0000;">3</span><span class="sc" style="color: #5E5E5E;">:</span><span class="dv" style="color: #AD0000;">0</span>,</span>
<span id="cb9-3">  <span class="sc" style="color: #5E5E5E;">~</span> <span class="fu" style="color: #4758AB;">heart_rate_zones</span>(</span>
<span id="cb9-4">    end <span class="sc" style="color: #5E5E5E;">-</span> <span class="fu" style="color: #4758AB;">months</span>(.x), </span>
<span id="cb9-5">    end <span class="sc" style="color: #5E5E5E;">-</span> <span class="fu" style="color: #4758AB;">months</span>(.x) <span class="sc" style="color: #5E5E5E;">+</span> <span class="fu" style="color: #4758AB;">months</span>(<span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb9-6">  )</span>
<span id="cb9-7">)</span>
<span id="cb9-8"></span>
<span id="cb9-9">steps <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">map_dfr</span>(</span>
<span id="cb9-10">  <span class="dv" style="color: #AD0000;">3</span><span class="sc" style="color: #5E5E5E;">:</span><span class="dv" style="color: #AD0000;">0</span>,</span>
<span id="cb9-11">  <span class="sc" style="color: #5E5E5E;">~</span> <span class="fu" style="color: #4758AB;">steps</span>(</span>
<span id="cb9-12">    end <span class="sc" style="color: #5E5E5E;">-</span> <span class="fu" style="color: #4758AB;">months</span>(.x), </span>
<span id="cb9-13">    end <span class="sc" style="color: #5E5E5E;">-</span> <span class="fu" style="color: #4758AB;">months</span>(.x) <span class="sc" style="color: #5E5E5E;">+</span> <span class="fu" style="color: #4758AB;">months</span>(<span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb9-14">  )</span>
<span id="cb9-15">)</span></code></pre></div>
</div>
<p>First, we can examine the heart rate data:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><span class="fu" style="color: #4758AB;">head</span>(hr)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 × 6
  date       zone         min_hr max_hr minutes_in_zone calories_out
  &lt;date&gt;     &lt;chr&gt;         &lt;int&gt;  &lt;int&gt;           &lt;int&gt;        &lt;dbl&gt;
1 2021-07-18 Out of Range     30    113            1440       2530. 
2 2021-07-18 Fat Burn        113    141               0          0  
3 2021-07-18 Cardio          141    176               0          0  
4 2021-07-18 Peak            176    220               0          0  
5 2021-07-19 Out of Range     30    113            1408       2689. 
6 2021-07-19 Fat Burn        113    141               9         86.6</code></pre>
</div>
</div>
<p>and the steps data:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><span class="fu" style="color: #4758AB;">head</span>(steps)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 × 2
  date       steps
  &lt;date&gt;     &lt;dbl&gt;
1 2021-07-18  5620
2 2021-07-19  7537
3 2021-07-20  5513
4 2021-07-21  9014
5 2021-07-22 10883
6 2021-07-23  2975</code></pre>
</div>
</div>
<p>Now, let’s plot them against each other.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1">df <span class="ot" style="color: #003B4F;">&lt;-</span> hr <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb14-2">  <span class="fu" style="color: #4758AB;">filter</span>(zone <span class="sc" style="color: #5E5E5E;">!=</span> <span class="st" style="color: #20794D;">"Out of Range"</span>) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb14-3">  <span class="fu" style="color: #4758AB;">group_by</span>(date) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb14-4">  <span class="fu" style="color: #4758AB;">summarize</span>(<span class="at" style="color: #657422;">total_minutes =</span> <span class="fu" style="color: #4758AB;">sum</span>(minutes_in_zone), <span class="at" style="color: #657422;">.groups =</span> <span class="st" style="color: #20794D;">"drop"</span>) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb14-5">  <span class="fu" style="color: #4758AB;">inner_join</span>(steps, <span class="at" style="color: #657422;">by =</span> <span class="st" style="color: #20794D;">"date"</span>)</span>
<span id="cb14-6">  </span>
<span id="cb14-7">df <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb14-8">  <span class="fu" style="color: #4758AB;">mutate</span>(<span class="at" style="color: #657422;">steps =</span> <span class="fu" style="color: #4758AB;">as.numeric</span>(steps)) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb14-9">  <span class="fu" style="color: #4758AB;">filter</span>(<span class="fu" style="color: #4758AB;">log</span>(total_minutes) <span class="sc" style="color: #5E5E5E;">&gt;</span> <span class="dv" style="color: #AD0000;">1</span>) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb14-10">  <span class="fu" style="color: #4758AB;">ggplot</span>(</span>
<span id="cb14-11">    <span class="fu" style="color: #4758AB;">aes</span>(</span>
<span id="cb14-12">      steps,</span>
<span id="cb14-13">      total_minutes</span>
<span id="cb14-14">    )</span>
<span id="cb14-15">  ) <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb14-16">  <span class="fu" style="color: #4758AB;">geom_point</span>() <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb14-17">  <span class="fu" style="color: #4758AB;">geom_smooth</span>(<span class="at" style="color: #657422;">method =</span> <span class="st" style="color: #20794D;">"lm"</span>, <span class="at" style="color: #657422;">se =</span> F) <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb14-18">  <span class="fu" style="color: #4758AB;">scale_x_log10</span>() <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb14-19">  <span class="fu" style="color: #4758AB;">scale_y_log10</span>()</span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.matthewrkaye.com/posts/2021-06-08-working-with-your-fitbit-data-in-r/static/rmarkdown-libsunnamed-chunk-11-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Or maybe it’d be interesting to predict your zone minutes from your steps:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1">df <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb15-2">  <span class="fu" style="color: #4758AB;">mutate</span>(<span class="at" style="color: #657422;">steps =</span> <span class="fu" style="color: #4758AB;">as.numeric</span>(steps)) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb15-3">  <span class="fu" style="color: #4758AB;">lm</span>(total_minutes <span class="sc" style="color: #5E5E5E;">~</span> steps, <span class="at" style="color: #657422;">data =</span> .) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb15-4">  broom<span class="sc" style="color: #5E5E5E;">::</span><span class="fu" style="color: #4758AB;">tidy</span>() <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb15-5">  <span class="fu" style="color: #4758AB;">mutate</span>(<span class="fu" style="color: #4758AB;">across</span>(<span class="fu" style="color: #4758AB;">where</span>(is.numeric), round, <span class="dv" style="color: #AD0000;">5</span>))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 5
  term        estimate std.error statistic p.value
  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
1 (Intercept) 23.1       5.78         4.00 0.00011
2 steps        0.00252   0.00056      4.53 0.00001</code></pre>
</div>
</div>
</section>
<section id="wrapping-up" class="level2">
<h2 class="anchored" data-anchor-id="wrapping-up">Wrapping Up</h2>
<p>And that’s it! Hopefully this helped show how <code>fitbitr</code> makes pulling your data easy, and gets you curious about the insights you can glean from your own data. The Fitbit API gives you access to so much interesting information about yourself, your habits, your fitness, and so much more, and <code>fitbitr</code> is just meant to be a door into that gold mine.</p>


</section>

 ]]></description>
  <category>R</category>
  <category>data science</category>
  <guid>https://www.matthewrkaye.com/posts/2021-06-08-working-with-your-fitbit-data-in-r/index.html</guid>
  <pubDate>Tue, 08 Jun 2021 04:00:00 GMT</pubDate>
</item>
<item>
  <title>Highlights From rstudio::global</title>
  <dc:creator>Matt Kaye</dc:creator>
  <link>https://www.matthewrkaye.com/posts/2021-02-11-highlights-from-rstudio-global/index.html</link>
  <description><![CDATA[ 



<p><code>rstudio::global</code>, this year’s iteration of the annual RStudio conference, was a few weeks ago. Here were some highlights:</p>
<section id="talks" class="level2">
<h2 class="anchored" data-anchor-id="talks">Talks</h2>
<p>There were a few talks I really loved:</p>
<ul>
<li><a href="https://rstudio.com/resources/rstudioglobal-2021/using-r-to-up-your-experimentation-game/">Using R to Up Your Experimentation Game</a>, by Shirbi Ish-Shalom. On experimentation, sequential testing, taking big swings, and being statistically rigorous</li>
<li><a href="https://rstudio.com/resources/rstudioglobal-2021/maintaining-the-house-the-tidyverse-built/">Maintaining the House the Tidyverse Built</a>, by Hadley Wickham. On building and maintaining the Tidyverse, and what package maintenance in the real world is like when you have millions of downloads.</li>
<li><a href="https://rstudio.com/resources/rstudioglobal-2021/organization-how-to-make-internal-r-packages-part-of-your-team/">oRganization: How to Make Internal R Packages Part of Your Team</a>, by Emily Riederer. On how using internal packages (like <code>collegeviner</code> at CollegeVine!) can improve your R workflow and make teamwork in R dramatically easier, smoother, and more efficient.</li>
<li><a href="https://rstudio.com/resources/rstudioglobal-2021/fairness-and-data-science-failures-factors-and-futures/">Fairness and Data Science: Failures, Factors, and Futures</a>, by Grant Fleming. On model fairness, bias, and evaluation techniques, and why they’re important to get right.</li>
</ul>
</section>
<section id="cool-new-things" class="level2">
<h2 class="anchored" data-anchor-id="cool-new-things">Cool New Things</h2>
<ul>
<li><code>finetune</code>, Max Kuhn’s new <code>tune</code>-adjacent package, is live (albeit a little buggy)! It has some cool new model tuning algorithms, including racing methods with <code>tune_race_anova()</code> and <code>tune_race_win_loss()</code>, in addition to my personal favorite: <code>tune_sim_anneal()</code> for Simulated Annealing! <a href="https://rstudio.com/resources/rstudioglobal-2021/whats-new-in-tidymodels/">Link to the talk</a></li>
<li>Major improvements to <code>shiny</code>, including some serious caching upgrades that’ll improve performance dramatically! <a href="https://rstudio.com/resources/rstudioglobal-2021/making-shiny-apps-faster-with-caching/">Link to the talk</a></li>
</ul>
</section>
<section id="other-highlights" class="level2">
<h2 class="anchored" data-anchor-id="other-highlights">Other Highlights</h2>
<ul>
<li>Meeting a bunch of people in the breakout sessions! This year, there were virtual “tables” where you could drag your avatar to “sit down”, and once you were close enough to a table you could hear all of its conversation.</li>
</ul>


</section>

 ]]></description>
  <category>R</category>
  <category>data science</category>
  <guid>https://www.matthewrkaye.com/posts/2021-02-11-highlights-from-rstudio-global/index.html</guid>
  <pubDate>Thu, 11 Feb 2021 05:00:00 GMT</pubDate>
</item>
<item>
  <title>What’s New in slackr 2.1.0</title>
  <dc:creator>Matt Kaye</dc:creator>
  <link>https://www.matthewrkaye.com/posts/2021-02-07-what-s-new-in-slackr-2-1-0/index.html</link>
  <description><![CDATA[ 



<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p><code>slackr 2.1.0+</code> is live! There are a whole bunch of exciting changes that we (mostly <a href="https://github.com/andrie">Andrie de Vries</a> and I) have made to improve the package a bunch.</p>
</section>
<section id="changes" class="level2">
<h2 class="anchored" data-anchor-id="changes">Changes</h2>
<p>Here are some of the things that are new in <code>slackr 2.1.0+</code>. For more info on the package, check out the <a href="https://github.com/mrkaye97/slackr">Github repo</a> and the <a href="https://mrkaye97.github.io/slackr/index.html">pkgdown site</a>.</p>
<section id="ease-of-use-improvements" class="level3">
<h3 class="anchored" data-anchor-id="ease-of-use-improvements">Ease of Use Improvements</h3>
<ul>
<li>We’ve dramatically improved error messaging, so long gone are the days of errors like <code>No 'id' column found in 'x'</code>! Now, error messages should be far more helpful, with some hints about what might be going wrong.</li>
<li>We’ve updated the package documentation significantly, so now there’s a far more informative <a href="https://github.com/mrkaye97/slackr">README</a>, some vignettes, and a <a href="https://mrkaye97.github.io/slackr/index.html">pkgdown site</a>.</li>
<li>We’ve more clearly described the different use cases for <code>slackr</code>, in order to better help users set up <code>slackr</code> in a way that makes sense for them.</li>
</ul>
</section>
<section id="new-features" class="level3">
<h3 class="anchored" data-anchor-id="new-features">New Features</h3>
<ul>
<li>We’ve fixed a bunch of bugs that were preventing things like <code>icon_emoji</code> and <code>username</code> from working, so those are fixed now!</li>
<li>We’ve brought back some old functions that were removed in <code>slackr 2.0.0</code>: <code>slackr_history()</code> and <code>slackr_delete()</code>. See the docs for descriptions of what these functions can do.</li>
</ul>
</section>
<section id="back-end-changes" class="level3">
<h3 class="anchored" data-anchor-id="back-end-changes">Back-End Changes</h3>
<p>We’ve made a ton of changes for how <code>slackr</code> interacts with the Slack API:</p>
<ul>
<li>We now allow paging, which is especially helpful when you have a workspace of more than 1000 channels.</li>
<li>We cache requests to get lists of channels and users so that we don’t need to repeat common API calls. This speeds up calls to <code>slackr_***()</code> and limits how often you need to actually hit the API.</li>
<li>We’ve gotten rid of a really nasty implementation of channel caching (writing a local cache to the disk) in favor of the method described above.</li>
<li>We’ve factored out API calls into a separate function, which makes the package easier to understand and test.</li>
<li>Speaking of testing, we’ve implemented a whole bunch of unit tests, and will be working on more.</li>
</ul>
</section>
<section id="deprecations" class="level3">
<h3 class="anchored" data-anchor-id="deprecations">Deprecations</h3>
<ul>
<li>We’ve deprecated a bunch of camel case functions in favor of their snake case counterparts for simplicity. Don’t worry! These are soft-deprecated for now. They won’t go away fully until a future version of <code>slackr</code></li>
<li>We’ve deprecated <code>text_slackr</code> in favor of <code>slackr_msg</code>, since they do basically the same thing.</li>
</ul>


</section>
</section>

 ]]></description>
  <category>R</category>
  <guid>https://www.matthewrkaye.com/posts/2021-02-07-what-s-new-in-slackr-2-1-0/index.html</guid>
  <pubDate>Sun, 07 Feb 2021 05:00:00 GMT</pubDate>
</item>
<item>
  <title>A Gentle Introduction to Markov Chains and MCMC</title>
  <dc:creator>Matt Kaye</dc:creator>
  <link>https://www.matthewrkaye.com/posts/2021-01-13-a-gentle-introduction-to-markov-chains-and-mcmc/index.html</link>
  <description><![CDATA[ 



<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Every other Friday at work we have a meeting called All Hands. During the first half of All Hands a member of the team gives a presentation, which is split up into two pieces: A personal presentation – your favorite food, TV shows, books, etc. – and a mini-lesson, which can be about any topic of interest that’s unrelated to work. Yesterday it was my turn, and I gave my mini-lesson on Markov Chains and Markov Chain Monte Carlo. This post memorializes what I covered.</p>
</section>
<section id="markov-chains" class="level1">
<h1>Markov Chains</h1>
<p>First, what is a Markov Chain? It’s easiest to break it down into it’s component parts. A <strong>Markov Chain</strong> is a <em>chain</em>, or sequence of events, that follow the Markov Property. And the Markov Property is pretty intuitive: The <strong>Markov Property</strong> says that the next state in a sequence (chain) is only dependent on the current state. Statisticians would call this “memorylessness,” and we can write out the property in its true mathematical form below, where <img src="https://latex.codecogs.com/png.latex?X"> is a random variable and <img src="https://latex.codecogs.com/png.latex?x%5C_%7Bt%7D"> is the probability distribution that <img src="https://latex.codecogs.com/png.latex?X"> takes on at time <img src="https://latex.codecogs.com/png.latex?t">.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ap(x_%7Bt+1%7D%20%7C%20x_%7Bt%7D,%20x_%7Bt-1%7D,%20x_%7Bt-2%7D,%20..%20x_%7B0%7D)%20=%20p(x_%7Bt+1%7D%20%7C%20x_%7Bt%7D)%0A"></p>
<p>In plain English, all this definition is saying is that if you are following the Markov Property, then where you go next is only determined by where you are now, and how you got to where you are has no impact. At the end of my talk, one of my coworkers commented that this property is actually quite beautiful in a real-world sense, and I feel the same way. It certainly could have been the example of a guiding principle that I choose to follow that I used in my personal presentation.</p>
<p>So, now that we know what a Markov Chain is, let’s walk through an example. The most commonly seen type of Markov Chain is called a <em>random walk</em>. Simply, a <strong>random walk</strong> is a Markov Chain where the next state is just determined by the current state plus some random noise. I’ve coded up an example below:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="do" style="color: #5E5E5E;
font-style: italic;">## library(purrr)</span></span>
<span id="cb1-2"><span class="do" style="color: #5E5E5E;
font-style: italic;">## library(magrittr)</span></span>
<span id="cb1-3"><span class="do" style="color: #5E5E5E;
font-style: italic;">## library(ggplot2)</span></span>
<span id="cb1-4"></span>
<span id="cb1-5">randomly_walk <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="cf" style="color: #003B4F;">function</span>(<span class="at" style="color: #657422;">.ix =</span> <span class="fu" style="color: #4758AB;">c</span>(), <span class="at" style="color: #657422;">n_steps =</span> <span class="dv" style="color: #AD0000;">100</span>) {</span>
<span id="cb1-6">  results <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">numeric</span>(n_steps)</span>
<span id="cb1-7">  <span class="cf" style="color: #003B4F;">for</span> (i <span class="cf" style="color: #003B4F;">in</span> <span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">:</span>(n_steps<span class="dv" style="color: #AD0000;">-1</span>)) {</span>
<span id="cb1-8">    results[i <span class="sc" style="color: #5E5E5E;">+</span> <span class="dv" style="color: #AD0000;">1</span>] <span class="ot" style="color: #003B4F;">&lt;-</span> results[i] <span class="sc" style="color: #5E5E5E;">+</span> <span class="fu" style="color: #4758AB;">rnorm</span>(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb1-9">  }</span>
<span id="cb1-10">  </span>
<span id="cb1-11">  <span class="fu" style="color: #4758AB;">return</span>(results)</span>
<span id="cb1-12">}</span>
<span id="cb1-13"></span>
<span id="cb1-14">(</span>
<span id="cb1-15">  random_walk <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">randomly_walk</span>() <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb1-16">    <span class="fu" style="color: #4758AB;">tibble</span>(<span class="at" style="color: #657422;">position =</span> .)</span>
<span id="cb1-17">)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 100 × 1
   position
      &lt;dbl&gt;
 1   0     
 2   0.546 
 3   0.0744
 4  -0.257 
 5   0.905 
 6   2.33  
 7   1.95  
 8   1.44  
 9   1.12  
10   1.83  
# … with 90 more rows</code></pre>
</div>
</div>
<p>That table shows a random walk with 100 steps, generated by adding standard normal noise to the position after each step. Let’s plot it and see what it looks like.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1">random_walk <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb3-2">  <span class="fu" style="color: #4758AB;">rownames_to_column</span>(<span class="at" style="color: #657422;">var =</span> <span class="st" style="color: #20794D;">'time'</span>) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb3-3">  <span class="fu" style="color: #4758AB;">mutate</span>(<span class="at" style="color: #657422;">time =</span> time <span class="sc" style="color: #5E5E5E;">%&gt;%</span> <span class="fu" style="color: #4758AB;">as.numeric</span>()) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb3-4">  <span class="fu" style="color: #4758AB;">ggplot</span>(<span class="fu" style="color: #4758AB;">aes</span>(time, position)) <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb3-5">  <span class="fu" style="color: #4758AB;">geom_line</span>() <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb3-6">  <span class="fu" style="color: #4758AB;">theme_minimal</span>()</span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.matthewrkaye.com/posts/2021-01-13-a-gentle-introduction-to-markov-chains-and-mcmc/static/rmarkdown-libsunnamed-chunk-3-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Cool! The walk starts at 0, and then jumps around randomly a bunch until <img src="https://latex.codecogs.com/png.latex?t=100">. It’ll be more interesting once we simulate 20 random walks.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1">n_steps <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="dv" style="color: #AD0000;">500</span></span>
<span id="cb4-2">n_chains <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="dv" style="color: #AD0000;">20</span></span>
<span id="cb4-3">twenty_walks <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">map</span>(</span>
<span id="cb4-4">  <span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">:</span>n_chains, </span>
<span id="cb4-5">  randomly_walk,</span>
<span id="cb4-6">  n_steps</span>
<span id="cb4-7">) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb4-8">  <span class="fu" style="color: #4758AB;">tibble</span>(<span class="at" style="color: #657422;">position =</span> .) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb4-9">  <span class="fu" style="color: #4758AB;">unnest</span>(<span class="at" style="color: #657422;">cols =</span> <span class="fu" style="color: #4758AB;">c</span>(position)) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb4-10">  <span class="fu" style="color: #4758AB;">mutate</span>(</span>
<span id="cb4-11">    <span class="at" style="color: #657422;">time =</span> <span class="fu" style="color: #4758AB;">rep</span>(<span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">:</span>n_steps, n_chains),</span>
<span id="cb4-12">    <span class="at" style="color: #657422;">walk =</span> <span class="fu" style="color: #4758AB;">map</span>(<span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">:</span>n_chains, rep, n_steps) <span class="sc" style="color: #5E5E5E;">%&gt;%</span> </span>
<span id="cb4-13">      <span class="fu" style="color: #4758AB;">unlist</span>() <span class="sc" style="color: #5E5E5E;">%&gt;%</span> </span>
<span id="cb4-14">      <span class="fu" style="color: #4758AB;">as.factor</span>()</span>
<span id="cb4-15">  )</span>
<span id="cb4-16"></span>
<span id="cb4-17">twenty_walks <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb4-18">  <span class="fu" style="color: #4758AB;">ggplot</span>() <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb4-19">  <span class="fu" style="color: #4758AB;">aes</span>(time, position, <span class="at" style="color: #657422;">color =</span> walk) <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb4-20">  <span class="fu" style="color: #4758AB;">geom_line</span>() <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb4-21">  <span class="fu" style="color: #4758AB;">theme_minimal</span>() <span class="sc" style="color: #5E5E5E;">+</span> </span>
<span id="cb4-22">  <span class="fu" style="color: #4758AB;">theme</span>(<span class="at" style="color: #657422;">legend.position =</span> <span class="st" style="color: #20794D;">'none'</span>)</span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.matthewrkaye.com/posts/2021-01-13-a-gentle-introduction-to-markov-chains-and-mcmc/static/rmarkdown-libsunnamed-chunk-4-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>So, what’s going on here? It basically looks how we’d expect. At any given time point, the mean position of the 20 is about zero, but the standard deviation of those positions goes up over time. Specifically, at any given time <img src="https://latex.codecogs.com/png.latex?t">, the standard deviation of the positions should be roughly equal to <img src="https://latex.codecogs.com/png.latex?%5Csqrt%20t">, because of how the variance is compounding. Remember, these random walks are Markov Chains because at every time <img src="https://latex.codecogs.com/png.latex?t">, I defined the position <img src="https://latex.codecogs.com/png.latex?y%5C_%7Bt+1%7D"> to be <img src="https://latex.codecogs.com/png.latex?y%5C_%7Bt%7D%20+%20%5Cmathcal%7BN%7D(0,%201)">, or the the next position is the current position plus a standard normal noise (i.e.&nbsp;zero-centered with unit variance).</p>
<p>Cool, so now we have an idea of what a Markov Chain is and how a random walk is an example of one. Now, why do we care? What kinds of problems can we solve with Markov Chains? It turns out that one thing we can use them to do is to calculate intractable integrals. What does this mean? Well, remembering back to a calculus class once upon a time, we know if we have some function <img src="https://latex.codecogs.com/png.latex?f(x)%20=%202x">, we can integrate that function by following a one of a couple of rules. In this case, that rule is to raise the coefficient in front of the <img src="https://latex.codecogs.com/png.latex?x"> to turn it into a power, such that the new exponent equals the old one plus one, and the new coefficient equals the old one divided by the new exponent. For <img src="https://latex.codecogs.com/png.latex?f(x)">, we find <img src="https://latex.codecogs.com/png.latex?F(x)%20=%20%5Cint%20f(x)%20=%20x%5E%7B2%7D%20+%20c">, where <img src="https://latex.codecogs.com/png.latex?c"> is a constant. However, in many applications, such as Bayesian statistics, we run into functions of hundreds or thousands of parameters that are intractable to integrate. In other words, even really, really powerful calculators can’t integrate them: there are just too many parameters. So, we’re stuck. How do we integrate a function that even a super powerful calculator can’t? In steps Markov Chain Monte Carlo, coming to the rescue.</p>
</section>
<section id="markov-chain-monte-carlo" class="level1">
<h1>Markov Chain Monte Carlo</h1>
<p>It turns out that we can use Markov Chains to approximate the integral in cases where we can’t calculate it directly. This is an incredible powerful discovery, and one that we’ve only been able to really take advantage of in the past twenty or so years, as computing power has grown exponentially. So, how do we actually do it? Let’s frame it as a simple problem that’s isomorphic to the actual problem at hand.</p>
<p>Imagine you are the ruler of an island kingdom, which has four islands. Island 1 has population 1, Island 2 has population 2, Island 3 has population 3, and Island 4 has population 4. And, imagine that you want to spend time on each island proportional to the percentage of the total population of your kingdom that it makes up. In other words, you want to spend 10% of your time on Island 1, and so on. But, you have a problem: You don’t know how to add. Imagine that the only mathematical operation you know how to do is divide. Can you figure out a way to spend your time how you want without being able to calculate the total population of your kingdom?</p>
<p>Most likely, how you’d solve this problem isn’t immediately obvious, but there are a few brilliant algorithms that help us achieve our goal. One of them is proposed to you by two of your friends, Metropolis and Hastings. I’ve coded up their suggestion below:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1">run_rwmh <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="cf" style="color: #003B4F;">function</span>(<span class="at" style="color: #657422;">n_iters =</span> <span class="dv" style="color: #AD0000;">1000</span>, <span class="at" style="color: #657422;">island_populations =</span> <span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">:</span><span class="dv" style="color: #AD0000;">4</span>) {</span>
<span id="cb5-2">  locations <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">numeric</span>(n_iters)</span>
<span id="cb5-3">  </span>
<span id="cb5-4">  <span class="do" style="color: #5E5E5E;
font-style: italic;">## randomly choose an island to start on</span></span>
<span id="cb5-5">  locations[<span class="dv" style="color: #AD0000;">1</span>] <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">sample</span>(island_populations, <span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb5-6"></span>
<span id="cb5-7">  <span class="cf" style="color: #003B4F;">for</span> (i <span class="cf" style="color: #003B4F;">in</span> <span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">:</span>(n_iters<span class="dv" style="color: #AD0000;">-1</span>)) {</span>
<span id="cb5-8">    </span>
<span id="cb5-9">    <span class="do" style="color: #5E5E5E;
font-style: italic;">## propose a new island to go to</span></span>
<span id="cb5-10">    proposal_island <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">sample</span>(<span class="fu" style="color: #4758AB;">setdiff</span>(island_populations, locations[i]), <span class="dv" style="color: #AD0000;">1</span>) </span>
<span id="cb5-11">    </span>
<span id="cb5-12">    <span class="do" style="color: #5E5E5E;
font-style: italic;">## if that island has more people, always go</span></span>
<span id="cb5-13">    <span class="cf" style="color: #003B4F;">if</span> (proposal_island <span class="sc" style="color: #5E5E5E;">&gt;</span> locations[i]) {</span>
<span id="cb5-14">      locations[i <span class="sc" style="color: #5E5E5E;">+</span> <span class="dv" style="color: #AD0000;">1</span>] <span class="ot" style="color: #003B4F;">&lt;-</span> proposal_island</span>
<span id="cb5-15">    } <span class="cf" style="color: #003B4F;">else</span> {</span>
<span id="cb5-16">      <span class="do" style="color: #5E5E5E;
font-style: italic;">## if it has fewer people, flip a coin with probability</span></span>
<span id="cb5-17">      <span class="do" style="color: #5E5E5E;
font-style: italic;">##   proportional to the ratio of the populations to</span></span>
<span id="cb5-18">      <span class="do" style="color: #5E5E5E;
font-style: italic;">##   decide whether to go or stay</span></span>
<span id="cb5-19">      acceptance_probability <span class="ot" style="color: #003B4F;">&lt;-</span> proposal_island <span class="sc" style="color: #5E5E5E;">/</span> locations[i]</span>
<span id="cb5-20">      locations[i <span class="sc" style="color: #5E5E5E;">+</span> <span class="dv" style="color: #AD0000;">1</span>] <span class="ot" style="color: #003B4F;">&lt;-</span> </span>
<span id="cb5-21">        <span class="fu" style="color: #4758AB;">sample</span>(</span>
<span id="cb5-22">          <span class="fu" style="color: #4758AB;">c</span>(proposal_island, locations[i]), <span class="dv" style="color: #AD0000;">1</span>, </span>
<span id="cb5-23">          <span class="at" style="color: #657422;">prob =</span> <span class="fu" style="color: #4758AB;">c</span>(acceptance_probability, <span class="dv" style="color: #AD0000;">1</span> <span class="sc" style="color: #5E5E5E;">-</span> acceptance_probability)</span>
<span id="cb5-24">        )</span>
<span id="cb5-25">    }</span>
<span id="cb5-26">  }</span>
<span id="cb5-27">  <span class="fu" style="color: #4758AB;">return</span>(locations)</span>
<span id="cb5-28">}</span></code></pre></div>
</div>
<p>Here’s the algorithm your friends propose:</p>
<ol type="1">
<li>Pick a random island to start on.</li>
<li>On each day, randomly select a new island to go to (the <strong>proposal island</strong>).</li>
<li>Do one of the following, depending on the populations of the islands:
<ol type="1">
<li>If the proposal island has more people than the current island, go to the proposal island.</li>
<li>If it has fewer people, then flip a coin with probability equal to the proposal island’s population divided by the current island’s. If the coin comes up heads, go to the proposal island.</li>
</ol></li>
<li>Do it again a bunch of times.</li>
</ol>
<p>So, how does this algorithm perform? Let’s try it out!</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><span class="fu" style="color: #4758AB;">run_rwmh</span>(<span class="at" style="color: #657422;">n_iters =</span> <span class="dv" style="color: #AD0000;">10</span>) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb6-2">  <span class="fu" style="color: #4758AB;">tibble</span>(<span class="at" style="color: #657422;">island =</span> .) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb6-3">  <span class="fu" style="color: #4758AB;">group_by</span>(island) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb6-4">  <span class="fu" style="color: #4758AB;">summarize</span>(<span class="at" style="color: #657422;">days_spent =</span> <span class="fu" style="color: #4758AB;">n</span>(), <span class="at" style="color: #657422;">.groups =</span> <span class="st" style="color: #20794D;">'drop'</span>) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb6-5">  <span class="fu" style="color: #4758AB;">mutate</span>(<span class="at" style="color: #657422;">day_proportion =</span> days_spent <span class="sc" style="color: #5E5E5E;">/</span> <span class="fu" style="color: #4758AB;">sum</span>(days_spent))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 4 × 3
  island days_spent day_proportion
   &lt;dbl&gt;      &lt;int&gt;          &lt;dbl&gt;
1      1          2            0.2
2      2          3            0.3
3      3          3            0.3
4      4          2            0.2</code></pre>
</div>
</div>
<p>Unsurprisingly, with only 10 iterations the algorithm does not perform particularly well. But what about if we give it a lot more time? Let’s try 10,000 iterations.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1">some_islands <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">run_rwmh</span>(<span class="at" style="color: #657422;">n_iters =</span> <span class="dv" style="color: #AD0000;">10000</span>) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb8-2">  <span class="fu" style="color: #4758AB;">tibble</span>(<span class="at" style="color: #657422;">island =</span> .) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb8-3">  <span class="fu" style="color: #4758AB;">group_by</span>(island) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb8-4">  <span class="fu" style="color: #4758AB;">summarize</span>(<span class="at" style="color: #657422;">days_spent =</span> <span class="fu" style="color: #4758AB;">n</span>(), <span class="at" style="color: #657422;">.groups =</span> <span class="st" style="color: #20794D;">'drop'</span>) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb8-5">  <span class="fu" style="color: #4758AB;">mutate</span>(<span class="at" style="color: #657422;">day_proportion =</span> days_spent <span class="sc" style="color: #5E5E5E;">/</span> <span class="fu" style="color: #4758AB;">sum</span>(days_spent),</span>
<span id="cb8-6">         <span class="at" style="color: #657422;">error_margin =</span> day_proportion <span class="sc" style="color: #5E5E5E;">/</span> (island <span class="sc" style="color: #5E5E5E;">/</span> <span class="fu" style="color: #4758AB;">sum</span>(island)) <span class="sc" style="color: #5E5E5E;">-</span> <span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb8-7"></span>
<span id="cb8-8">mean_error_margin <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">mean</span>(some_islands<span class="sc" style="color: #5E5E5E;">$</span>error_margin)</span>
<span id="cb8-9">sd_error_margin <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">sd</span>(some_islands<span class="sc" style="color: #5E5E5E;">$</span>error_margin)</span>
<span id="cb8-10">some_islands</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 4 × 4
  island days_spent day_proportion error_margin
   &lt;dbl&gt;      &lt;int&gt;          &lt;dbl&gt;        &lt;dbl&gt;
1      1       1002          0.100      0.00200
2      2       1940          0.194     -0.0300 
3      3       3023          0.302      0.00767
4      4       4035          0.404      0.00875</code></pre>
</div>
</div>
<p>Much better! After 10,000 iterations, we’re spending almost the exact proportion of time on each island that we want to be, as evidenced by the tiny error margins. In addition, the standard deviation of the error margins is 0.01831, which is tiny. That’s awesome! But what about if the system is more complex? Like, what if we had 100 islands?</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1">more_islands <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">run_rwmh</span>(<span class="at" style="color: #657422;">n_iters =</span> <span class="dv" style="color: #AD0000;">10000</span>, <span class="at" style="color: #657422;">island_populations =</span> <span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">:</span><span class="dv" style="color: #AD0000;">100</span>) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb10-2">  <span class="fu" style="color: #4758AB;">tibble</span>(<span class="at" style="color: #657422;">island =</span> .) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb10-3">  <span class="fu" style="color: #4758AB;">group_by</span>(island) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb10-4">  <span class="fu" style="color: #4758AB;">summarize</span>(<span class="at" style="color: #657422;">days_spent =</span> <span class="fu" style="color: #4758AB;">n</span>(), <span class="at" style="color: #657422;">.groups =</span> <span class="st" style="color: #20794D;">'drop'</span>) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb10-5">  <span class="fu" style="color: #4758AB;">mutate</span>(<span class="at" style="color: #657422;">day_proportion =</span> days_spent <span class="sc" style="color: #5E5E5E;">/</span> <span class="fu" style="color: #4758AB;">sum</span>(days_spent),</span>
<span id="cb10-6">         <span class="at" style="color: #657422;">error_margin =</span> day_proportion <span class="sc" style="color: #5E5E5E;">/</span> (island <span class="sc" style="color: #5E5E5E;">/</span> <span class="fu" style="color: #4758AB;">sum</span>(island)) <span class="sc" style="color: #5E5E5E;">-</span> <span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb10-7"></span>
<span id="cb10-8">mean_error_margin <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">mean</span>(more_islands<span class="sc" style="color: #5E5E5E;">$</span>error_margin)</span>
<span id="cb10-9">sd_error_margin <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">sd</span>(more_islands<span class="sc" style="color: #5E5E5E;">$</span>error_margin)</span>
<span id="cb10-10">more_islands</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 100 × 4
   island days_spent day_proportion error_margin
    &lt;dbl&gt;      &lt;int&gt;          &lt;dbl&gt;        &lt;dbl&gt;
 1      1          2         0.0002       0.0100
 2      2          8         0.0008       1.02  
 3      3          4         0.0004      -0.327 
 4      4          6         0.0006      -0.243 
 5      5          8         0.0008      -0.192 
 6      6         13         0.0013       0.0942
 7      7         22         0.0022       0.587 
 8      8         14         0.0014      -0.116 
 9      9         11         0.0011      -0.383 
10     10         16         0.0016      -0.192 
# … with 90 more rows</code></pre>
</div>
</div>
<p>No problem! Even with the extra islands, the mean error margin is still zero, and the standard deviation of the error margins is 0.18309, which is also small, but not as small as the simpler system. It’s true that a more complex system (i.e.&nbsp;more islands) would mean that we need more iterations to converge in probability to the proportions we’re shooting for, but the algorithm will still work with enough time. Let’s try running it one more time on the complex system, but this time with a million iterations.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1">more_iters <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">run_rwmh</span>(<span class="at" style="color: #657422;">n_iters =</span> <span class="dv" style="color: #AD0000;">1000000</span>, <span class="at" style="color: #657422;">island_populations =</span> <span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">:</span><span class="dv" style="color: #AD0000;">100</span>) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb12-2">  <span class="fu" style="color: #4758AB;">tibble</span>(<span class="at" style="color: #657422;">island =</span> .) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb12-3">  <span class="fu" style="color: #4758AB;">group_by</span>(island) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb12-4">  <span class="fu" style="color: #4758AB;">summarize</span>(<span class="at" style="color: #657422;">days_spent =</span> <span class="fu" style="color: #4758AB;">n</span>(), <span class="at" style="color: #657422;">.groups =</span> <span class="st" style="color: #20794D;">'drop'</span>) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb12-5">  <span class="fu" style="color: #4758AB;">mutate</span>(<span class="at" style="color: #657422;">day_proportion =</span> days_spent <span class="sc" style="color: #5E5E5E;">/</span> <span class="fu" style="color: #4758AB;">sum</span>(days_spent),</span>
<span id="cb12-6">         <span class="at" style="color: #657422;">error_margin =</span> day_proportion <span class="sc" style="color: #5E5E5E;">/</span> (island <span class="sc" style="color: #5E5E5E;">/</span> <span class="fu" style="color: #4758AB;">sum</span>(island)) <span class="sc" style="color: #5E5E5E;">-</span> <span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb12-7"></span>
<span id="cb12-8">mean_error_margin <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">mean</span>(more_iters<span class="sc" style="color: #5E5E5E;">$</span>error_margin)</span>
<span id="cb12-9">sd_error_margin <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">sd</span>(more_iters<span class="sc" style="color: #5E5E5E;">$</span>error_margin)</span>
<span id="cb12-10">more_iters</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 100 × 4
   island days_spent day_proportion error_margin
    &lt;dbl&gt;      &lt;int&gt;          &lt;dbl&gt;        &lt;dbl&gt;
 1      1        210       0.00021       0.0605 
 2      2        388       0.000388     -0.0203 
 3      3        624       0.000624      0.0504 
 4      4        808       0.000808      0.0201 
 5      5       1013       0.00101       0.0231 
 6      6       1218       0.00122       0.0252 
 7      7       1378       0.00138      -0.00587
 8      8       1579       0.00158      -0.00326
 9      9       1846       0.00185       0.0358 
10     10       1934       0.00193      -0.0233 
# … with 90 more rows</code></pre>
</div>
</div>
<p>Looks like that did the trick! The standard deviation of the error margins fell to 0.01698, just as we expected.</p>
<p>This algorithm is called the Metropolis-Hastings Algorithm, and it’s one of many in the class of Markov Chain Monte Carlo algorithms. Some others are the Gibbs Sampler and Hamiltonian Monte Carlo, both of which are frequently used in Bayesian statistics for estimating the parameters of regression models with hundreds of thousands of parameters. In short, these algorithms allow us to solve problems that were literally impossible to solve only two decades ago or so, which is an amazing feat!</p>
</section>
<section id="recap" class="level1">
<h1>Recap</h1>
<ul>
<li>Markov Chains are not that scary! They’re just a memoryless sequence of events, meaning that where you came from doesn’t impact where you go next.</li>
<li>Markov Chain Monte Carlo algorithms like the Metropolis-Hastings can be quite simple, and let us solve impossibly hard problems.</li>
</ul>


</section>

 ]]></description>
  <category>data science</category>
  <guid>https://www.matthewrkaye.com/posts/2021-01-13-a-gentle-introduction-to-markov-chains-and-mcmc/index.html</guid>
  <pubDate>Wed, 13 Jan 2021 05:00:00 GMT</pubDate>
</item>
<item>
  <title>What I’ve Been Drinking in Quarantine (Plus a Cocktail Lesson)</title>
  <dc:creator>Matt Kaye</dc:creator>
  <link>https://www.matthewrkaye.com/posts/2021-01-10-what-i-ve-been-drinking-in-quarantine/index.html</link>
  <description><![CDATA[ 



<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>The past ten-or-so months of limited activity due to Covid-19 have been a slog for everyone, to say the least. I’ve been fortunate to have avoided the worst of it, having spent much of the past ten months living in rural northwestern Connecticut.</p>
<p>Many of us have had lots of time to explore hobbies over this time, and something that has gained lots of popularity – editor’s note: unsurprisingly – is drinking! In particular, there seems to have been a surge in home bartending and cocktail lessons happening during Covid, since hobbyist bartending – which has been, and continues to be, a hobby of mine – is a great Covid activity! By bartending, you get to learn about cocktails and build your skills to impress your friends when social gatherings start happening again, and you get to drink during it! What could be better than that?</p>
</section>
<section id="what-ive-been-drinking" class="level1">
<h1>What I’ve Been Drinking</h1>
<p>So, what have I been drinking? First, some favorites of mine. I’m a big fan of the following miscellanea:</p>
<ul>
<li>IPAs (especially New England IPAs)</li>
<li>Amari (Cynar, Fernet, and Campari)</li>
<li>Islay Scotch</li>
<li>Tequila and Mezcal</li>
<li>Cocktails</li>
</ul>
<p>Generally, my drinks involve at least one those items. So, with that, some favorites from the past few months!</p>
<section id="beers-ive-been-loving" class="level2">
<h2 class="anchored" data-anchor-id="beers-ive-been-loving">Beers I’ve Been Loving</h2>
<ul>
<li>Green, Very Green, Juice Machine, and Haze by Tree House Brewing Company in Charlton, MA. Bascially, you can’t go wrong with Tree House. It’s one of the best breweries in the country, is all over the top ratings on Untappd, and makes almost univerally awesome beer. The ones I’ve listed are all very hazy, juicy, fruity (although not as much as some others, like Saturated and Iridescent) New England Style IPAs. That means they’re a little less bitter, a little less hoppy, and a little more like drinking orange juice than some of the other IPAs you’ve probably had elsewhere (Goose Island, Dogfish Head, etc.).</li>
<li>Focal Banger and Heady Topper from The Alchemist in Stowe, VT. Similar to Tree House, The Alchemist is a wildly popular New England brewery with some awesome beers. I’ve liked all of the ones I’ve tried, but Heady Topper and Focal Banger are especially awesome. I actually prefer the two of them to most of the Tree House beers (bar Very Green, probably). They’re both a little less fruity than the Tree Houses, which I prefer.</li>
<li>You Drive Us Wild, by Grimm in New York City. This is another beer with a similar profile to the Tree House / Alchemist groups (are you sensing a pattern?). Grimm is also an awesome brewery, and I’ve loved almost everything of theirs that I’ve had. Magnetic Compass and Tesseract are other highlights.</li>
</ul>
</section>
<section id="liquors-and-amari-ive-been-drinking" class="level2">
<h2 class="anchored" data-anchor-id="liquors-and-amari-ive-been-drinking">Liquors and Amari I’ve Been Drinking</h2>
<p>These are my go-to glasses to sip on. Generally, liquor before or during dinner, and amaro after dinner. “Amaro” is the Italian word for bitter, so reader beware: the amari (especially Fernet) are very bitter.</p>
<ul>
<li>Lagavulin 8 Year</li>
<li>Del Maguey Chichicapa</li>
<li>Tequila Ocho Plata</li>
<li>Cynar</li>
<li>Campari</li>
<li>Fernet Branca</li>
</ul>
</section>
<section id="cocktails" class="level2">
<h2 class="anchored" data-anchor-id="cocktails">Cocktails</h2>
<p>So, now for the main event. As promised, some great cocktails to try! A preface: I like a weird profile of cocktail. I’m not huge on sweet drinks, so the overly sweet margaritas from your neighborhood cantina aren’t what you’ll find here. I like sour, bitter, smoky, spicy, and herbal with just a touch of sweet. I’ll start with a few simple drinks (just a few easy to find ingredients), and then go through a couple of favorites that are a little more niche. At the end, I’ll give some general pointers on general cocktail making things and ingredients.</p>
<section id="negroni" class="level3">
<h3 class="anchored" data-anchor-id="negroni">Negroni</h3>
<p>The Negroni is my all time favorite drink. It’s bitter, sweet, complex, and easy to make! Traditionally, it’s equal parts gin, Campari, and sweet vermouth:</p>
<ul>
<li>1oz gin</li>
<li>1oz Campari</li>
<li>1oz sweet vermouth</li>
<li>Orange or lemon twist garnish</li>
</ul>
<p>Add as much ice as you can fit into a beaker or other glass that you can stir in, and add the ingredients. Stir about thirty seconds until the glass is well chilled. Strain into the glass of your choosing. Garnish.</p>
<p>For a Negroni, you probably want a neutral, London dry style gin. I’ve found that Beefeater works great, and isn’t particularly expensive. The vermouth is the most important piece here, as it gives all kinds of interesting flavors to the drink depending on the brand you use. You’ll want to spend the extra few dollars to get something great, like Carpano Antica.</p>
<p>Personally, as a mezcal lover, I often find myself swapping out the gin in my Negronis for Del Maguey Vida, which is a high-quality mezcal that’s great for making cocktails with. I’ve also found that using apple brandy is delicious as well, and using bourbon gets you close to a Boulevardier. Feel free to experiment!</p>
</section>
<section id="manhattan" class="level3">
<h3 class="anchored" data-anchor-id="manhattan">Manhattan</h3>
<p>The Manhattan is another classic. I use rye in mine, but you can get away with bourbon too (although you might get weird from bartenders are certain bars for doing so).</p>
<ul>
<li>2oz rye whiskey</li>
<li>1oz sweet vermouth</li>
<li>4-6 dashes of bitters</li>
<li>Maraschino cherry garnish</li>
</ul>
<p>Add as much ice as you can fit into a beaker or other glass that you can stir in, and add the ingredients (preferably bitters-first so they don’t just sit on top of the ice). Stir about thirty seconds until the glass is well chilled. Strain into the glass of your choosing. Garnish.</p>
<p>Since the Manhattan is so simple, you really need to use high quality ingredients. I’ve found Rittenhouse Rye to be a fantastic rye, especially given the price. As before, you probably want Carpano Antica for the vermouth.</p>
</section>
<section id="margarita" class="level3">
<h3 class="anchored" data-anchor-id="margarita">Margarita</h3>
<p>Yet another classic, everyone’s familiar with a margarita. It’s simple and delicious.</p>
<ul>
<li>2oz tequila</li>
<li>1oz lime juice</li>
<li>.75oz triple sec, Cointreau, or 1:1 simple syrup</li>
</ul>
<p>Add ingredients to a shaker with as much ice as you can fit and shake vigorously for 30 seconds until the shaker is well chilled. Double strain into your glass of choice. Optionally, you can salt the rim of your glass.</p>
<p>You have some options for this one. Again, as a mezcal lover, I often swap the tequila for mezcal (or go 50/50). I also prefer less sweet drinks, so if .75oz of sugary stuff isn’t enough for you, just add some more!</p>
</section>
<section id="moscow-mule" class="level3">
<h3 class="anchored" data-anchor-id="moscow-mule">Moscow Mule</h3>
<p>The copper cup drink, and a super easy, delicious vodka cocktail.</p>
<ul>
<li>2oz vodka</li>
<li>3-5oz ginger beer, depending on how strong you like it</li>
<li>squeeze of lime juice</li>
</ul>
<p>For this one, I normally just add the ingredients to a glass, stir, and sip away! Using more ginger beer will mellow out the drink a lot.</p>
<p>Now, with some delicious, easy classics that won’t let you down out of the way, on to some more involved drinks! Some of these require harder-to-find ingredients (or just more ingredients), but I think they’re all delicious and worth a shot.</p>
</section>
<section id="last-word" class="level3">
<h3 class="anchored" data-anchor-id="last-word">Last Word</h3>
<p>The Last Word is an interesting one. It’s sweet, sour, herbal, and definitely not everybody’s cup of tea. It’s another easy equal-parter:</p>
<ul>
<li>.75oz lime juice</li>
<li>.75oz green Chartreuse</li>
<li>.75oz Luxardo Maraschino liqueur</li>
<li>.75oz gin</li>
<li>Maraschino cherry garnish</li>
</ul>
<p>Add the ingredients to a cocktail shaker with as much ice as you can fit, and shake vigorously for about 30 seconds until the shaker is well chilled. Double strain into your glass of choice.</p>
<p>This is a weird mix of ingredients, but it comes together to make a complex, delicious drink! For the adventurous, it’s definitely worth a shot.</p>
</section>
<section id="jungle-bird" class="level3">
<h3 class="anchored" data-anchor-id="jungle-bird">Jungle Bird</h3>
<p>The Jungle Bird is a bitter drink fan’s tiki drink. It’s a delicious mix of tiki and bitter, and is a real crowd-pleaser.</p>
<ul>
<li>1.5oz dark rum</li>
<li>1.5oz pineapple juice</li>
<li>.75oz Campari</li>
<li>.5oz lime juice</li>
<li>.5oz 1:1 simple syrup</li>
</ul>
<p>Add the ingredients to a cocktail shaker with as much ice as you can fit, and shake vigorously for about 30 seconds until the shaker is well chilled. Double strain into your glass of choice.</p>
<p>The Jungle Bird is another favorite of mine. It’s not too bitter, not too sweet, and you also get some lime and pineapple in there, which I love both of. It’s a tough one to go wrong with, since it’s not as strong as something like a Manhattan, less bitter than a Negroni, and less sweet than a Margarita can be.</p>
</section>
<section id="corpse-reviver-2" class="level3">
<h3 class="anchored" data-anchor-id="corpse-reviver-2">Corpse Reviver #2</h3>
<p>Another personal favorite of mine! The middle child of a trio of Corpse Revivers, I find this one to be totally delicious. Probably named for being the drink that’ll get you on your feet the next morning (need confirmation on that).</p>
<ul>
<li>1.5oz gin</li>
<li>1.5oz Lillet Blanc</li>
<li>1.5oz lemon juice</li>
<li>.75oz triple sec or Cointreau</li>
<li>&lt;.25 (small dash) absinthe, Pernod, or green Chartreuse</li>
</ul>
<p>Add the ingredients to a cocktail shaker with as much ice as you can fit, and shake vigorously for about 30 seconds until the shaker is well chilled. Double strain into your glass of choice.</p>
<p>This is another personal favorite. It’s sour, a little sweet, and very complex. The Lillet adds a lot of character and plays really well with the lemon and the herbal notes from the absinthe.</p>
</section>
<section id="enzoni" class="level3">
<h3 class="anchored" data-anchor-id="enzoni">Enzoni</h3>
<p>The Enzoni is a remix of the Negroni that’s a little sweeter, and uses fresh grapes! It’s equally delicious, and similar in profile to a Jungle Bird (a little sweet and less bitter than the Negroni).</p>
<ul>
<li>1oz gin</li>
<li>1oz Campari</li>
<li>.75oz lemon juice</li>
<li>.5oz 1:1 simple syrup</li>
<li>5 white grapes</li>
</ul>
<p>Muddle the grapes with the simple syrup in the bottom of a cocktail shaker. Then, add as much ice as you can with the rest of the ingredients, and shake vigorously for about 30 seconds until the shaker is well chilled. Double strain into your glass of choice.</p>
<p>The Enzoni is an awesome drink. The acidity from the lemon and the sweetness and flavor from the grapes make this a unique and delicious drink.</p>
</section>
<section id="bitter-giusseppe" class="level3">
<h3 class="anchored" data-anchor-id="bitter-giusseppe">Bitter Giusseppe</h3>
<p>Finally, a bitters-forward drink! The Bitter Giusseppe is simple, and checks a lot of boxes for me. It’s sour and bitter, and it’s also a low alcohol content drink!</p>
<ul>
<li>2oz Cynar</li>
<li>1oz sweet vermouth</li>
<li>.25oz lemon juice</li>
<li>4 dashes of bitters</li>
</ul>
<p>Add as much ice as you can fit into a cocktail shaker with the ingredients and shake vigorously for about 30 seconds until the shaker is well chilled. Double strain into your glass of choice.</p>
<p>As usual, you probably want to be using Carpano Antica as your vermouth here. It adds a lot of interesting flavors to the drink. This one is awesome for an easy sipper, and the acidity from the lemon really takes it over the top</p>
</section>
</section>
<section id="general-pointers" class="level2">
<h2 class="anchored" data-anchor-id="general-pointers">General Pointers</h2>
<section id="cocktail-making" class="level3">
<h3 class="anchored" data-anchor-id="cocktail-making">Cocktail Making</h3>
<ol type="1">
<li>The reason we shake or stir our drinks is not to mix the ingredients together. Well, it is, but that’s not the primary reason. We’re shaking or stirring to <em>dilute</em> the drink. If you want an example of the importance of dilution, try making a Negroni in a glass without any ice, and just stir it together and taste it. Unless you like an extremely alcohol-forward, bitter drink (which you might, I do), you’ll probably like it far better after stirring with ice. The dilution and chilling of the drink does a lot to enhance the flavor, make the drink more enjoyable, and take the edge off. Don’t skip it!</li>
<li>Your ingredients <em>matter</em>. High quality ingredients will make better tasting drinks. You really don’t want to be trying to mask bad rye in a Manhattan, for example. You want to be showcasing a great rye!</li>
<li>Speaking of ingredients: squeeze your own juice, or at least your own lemon and lime juice. The stuff from the bottle with all of the preservatives is just not the same. If you don’t believe me, do a blind taste test of a margarita made with fresh lime juice vs.&nbsp;one with bottled juice, and see what you think. It’s worth it.</li>
<li>You can (and should) make your own simple syrup! It’s easy and takes two minutes, so there’s no reason to spend $7 on a small bottle from the store. All of my recipes call for 1:1 syrup, which means 1 part sugar, 1 part water. If you’re making it, that just means put a cup of sugar and a cup of water in a pot and heat it up <em>gently</em> until the sugar is dissolved. It will keep in the fridge for about a month. If you make 2:1 syrup, cut the amounts in the recipes in half. 2:1 syrup will keep in the fridge for far longer than 1:1 syrup.</li>
</ol>
</section>
<section id="ingredients" class="level3">
<h3 class="anchored" data-anchor-id="ingredients">Ingredients</h3>
<ol type="1">
<li>Buy lemons and limes. It makes all the difference in your drinks.</li>
<li>There are a lot of different types of liquor discussed here. These are the brands I like, but feel free to experiment with others! The key is to make drinks you like:
<ul>
<li><strong>Gin</strong> I use Beefeater for everything. It’s relatively inexpensive, available everywhere, and a great, neutral-flavored London dry gin. For a more herbal gin, go for Hendricks.</li>
<li><strong>Tequila</strong> This is a blog post in itself. At the very least, get a 100% agave tequila. Espolón and Olmeca Altos are good choices. If you want sipping tequila, you want to be buying something from a NOM (producer) who doesn’t use diffusers or autoclaves. This means <strong>NOT</strong> Clase Azul, Casamigos, or Patron. Good tequilas are fermented in barrels after the agave is roasted in ovens made of brick or stone, and NOMs using diffusers and autoclaves are cutting corners by using chemicals and high-pressure chambers to decrease their costs and speed up the process. The product suffers as a result, and they often mask bad product by adding sugar to their tequilas, which is why many people will tell you that Clase Azul is “smooth.” It is. That’s added sugar making it taste like that. There are a number of great (harder to find) tequilas that are both great for drinking and an opportunity to support distillers doing things the right way. A few that I love are Fortaleza, Tapatio, Tequila Ocho, and Siete Leguas.</li>
<li><strong>Mezcal</strong> Everything by Del Maguey is great. Chichicapa is an incredible sipping mezcal (but more expensive), and I use Vida for all of my mezcal cocktails.</li>
<li><strong>Vodka</strong> Expensive vodka is <em>not</em> necessarily good vodka. Personally, I strongly dislike Tito’s, Absolut, and Grey Goose. I’ve found that Tower (from Texas), Smirnoff, and Russian Standard all work fine, and are all far less expensive. A good vodka should taste and smell like nothing, and that’s basically what all three of those vodkas will give you. If you want to impress your friends, fill a Grey Goose bottle with Smirnoff.</li>
<li><strong>Rye</strong> As I said before, I’ve had great success with Rittenhouse. It’s a great rye, and it’s not very expensive. Knob Creek is also great if you want to spend the extra money.</li>
<li><strong>Bourbon</strong> If you want to use bourbon in a Manhattan (or just to sip), two that I like a lot are Buffalo Trace and Maker’s Mark.</li>
<li><strong>Rum</strong> For white rum, I normally just use Bacardi Superior. Plantation is another good one, albeit slightly more expensive. Dark rum preferences will depend on your taste, as some are much sweeter than others. Again, Plantation makes good rum. Or, if you’re ever traveling abroad post-Covid and want to bring back Havana Club Especial duty free, I’d recommend that. We can’t buy it in the U.S. because of the trade embargo with Cuba, which is a shame for many reasons, including Havana Club being great rum.</li>
</ul></li>
<li>Other ingredients
<ul>
<li><strong>Vermouth</strong> Dolin is fine, Carpano is great. Spend the extra money, it’s worth it.</li>
<li><strong>Ginger Beer, Tonic, etc.</strong> My personal favorite brand for mixers is Fever Tree. Their stuff is a little more expensive, but it’s worth it. It’s all great, and will make your drinks even better.</li>
</ul></li>
<li>Pro-tip: Lots of better bars and restaurants will have a secret “bartender’s choice” option that isn’t listed on the menu. This is a great way to broaden your cocktail horizons. Historically, I’ve just asked for things like “A mezcal drink that’s a little smoky, sour, or bitter, but not too sweet” and have discovered some great drinks! The key is letting a knowledgeable bartender know in broad strokes what you like, and letting them be creative!</li>
<li>Experiment, and make drinks you like! At the end of the day, you’re drinking for you, so why not enjoy your drink while you’re at it?</li>
</ol>


</section>
</section>
</section>

 ]]></description>
  <category>food + bev</category>
  <guid>https://www.matthewrkaye.com/posts/2021-01-10-what-i-ve-been-drinking-in-quarantine/index.html</guid>
  <pubDate>Sun, 10 Jan 2021 05:00:00 GMT</pubDate>
</item>
<item>
  <title>Our 2021 Big Data Bowl Submission</title>
  <dc:creator>Matt Kaye</dc:creator>
  <link>https://www.matthewrkaye.com/posts/2021-01-07-our-2021-big-data-bowl-submission/index.html</link>
  <description><![CDATA[ 



<section id="meta" class="level2">
<h2 class="anchored" data-anchor-id="meta">Meta</h2>
<p>This post is my team’s 2021 NFL Big Data Bowl submission. My team was made up of me, Hugh McCreery (Baltimore Orioles), John Edwards (Seattle Mariners), and Owen McGrattan (DS student at Berkeley). I’m proud of what we’ve put forth here, and hopefully you find it interesting. At the end (after the Appendix), I’ve added some overall thoughts on things we were curious about or feel like we could have done better, as well as what we view as the biggest strengths and weaknesses of our submission. Enjoy!</p>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Our project aims to measure the ability of defensive backs at performing different aspects of their defensive duties: deterring targets (either by reputation or through good positioning), closing down receivers, and breaking up passes. We do this by fitting four models, two for predicting the probability that a receiver will be targeted on a given play and two for predicting the probability that a pass will be caught, which we then use to aggregate the contributions of defensive backs over the course of the season.</p>
</section>
<section id="modeling-framework" class="level2">
<h2 class="anchored" data-anchor-id="modeling-framework">Modeling Framework</h2>
<p>We opted to use XGBoost for all of our models. At a high level, we chose a tree booster for its ability to find complex interactions between predictors, something we anticipated would be necessary for this project. Tree boosting also allows for null values to be present, which helped us divvy up credit in the catch probability models (more on this later). Finally, tree boosting is a relatively simple, easy-to-tune algorithm that generally performs extremely well, as was the case for us.</p>
</section>
<section id="catch-probability" class="level2">
<h2 class="anchored" data-anchor-id="catch-probability">Catch Probability</h2>
<p>Our catch probability model has two distinct components: The catch probability at throw time – as in, the chance that the pass is caught at the time the quarterback releases the ball – and the catch probability at arrival time – the chance the pass is caught at the time the ball arrives. These probabilities are distinct since a lot can happen between throw release and throw arrival. First, we will walk through the features that are used in building each model.</p>
<p>For the throw time model (which we will refer to as the “throw” model) and the arrival time model (the “arrival” model), the most important predictors by variable importance were what we expected entering this project: the distance of the receiver to the closest defender, the position of the receiver in the <img src="https://latex.codecogs.com/png.latex?y"> direction (i.e.&nbsp;distance from the sideline), the distance of the throw, the position of the football in the <img src="https://latex.codecogs.com/png.latex?y"> direction at arrival time (this is mostly catching throws to the sideline and throw aways), the velocity of the throw, the velocity and acceleration of the targeted receiver, and a composite receiver skill metric. For the arrival model, we use many of the same features. However, we do not account for the distance of the defenders to the throw vector – which accounts for the ability to break up a pass mid-flight – because the throw has already arrived.</p>
<p>These two models both perform quite well, and far better than random chance. The throw model accurately predicts <img src="https://latex.codecogs.com/png.latex?74%5C%25"> of all passes, with strong precision (<img src="https://latex.codecogs.com/png.latex?84%5C%25">) and recall (<img src="https://latex.codecogs.com/png.latex?76%5C%25">), and an AUC of <img src="https://latex.codecogs.com/png.latex?0.81">. As can be expected, our arrival model outperforms the throw model in all measures - accurately predicting <img src="https://latex.codecogs.com/png.latex?78%5C%25"> of all passes with a precision of <img src="https://latex.codecogs.com/png.latex?88%5C%25">, a recall of <img src="https://latex.codecogs.com/png.latex?79%5C%25">, and an AUC of <img src="https://latex.codecogs.com/png.latex?.87">. All of these metrics were calculated on a held-out data set not used in model training. Below are plots of the calibration of the predictions of each of the models on the same held-out set.</p>
<p><img src="https://www.matthewrkaye.com/posts/2021-01-07-our-2021-big-data-bowl-submission/https:/raw.githubusercontent.com/hjmbigdatabowl/bdb2021/main/inst/plots/calplot_a.png" class="img-fluid" alt="cal_plot_arrival_model"> <img src="https://www.matthewrkaye.com/posts/2021-01-07-our-2021-big-data-bowl-submission/https:/raw.githubusercontent.com/hjmbigdatabowl/bdb2021/main/inst/plots/calplot_t.png" class="img-fluid" alt="cal_plot_throw_model"></p>
<p>We can do a few particularly interesting things with the predictions from these two models in tandem. Namely, we can use the two to calculate marginal effects of the play of the defensive backs. A simple example is as follows: For a given pass attempt, our throw model estimates that there is a <img src="https://latex.codecogs.com/png.latex?80%5C%25"> chance of a catch. By the time that pass arrives, however, our arrival model estimates instead that there is a <img src="https://latex.codecogs.com/png.latex?50%5C%25"> chance of a catch. Ultimately, the play results in a drop. In total, our defense can get credit for <img src="https://latex.codecogs.com/png.latex?+.8"> drops, but we can break it down into <img src="https://latex.codecogs.com/png.latex?+.3"> drops worth from closing on the receiver and <img src="https://latex.codecogs.com/png.latex?+.5"> drops from breaking up the play, based on how the individual components differ. In other words, we subtract the probability of a catch at arrival time from the probability at throw time to get the credit for closing down the receiver, and we subtract the true outcome of the play from the probability of a catch at arrival time to get the credit for breaking up the pass.</p>
<p>The main challenge comes not from calculating the overall credit on the play, but from the distribution of credit <em>among</em> the defenders. In the previous example where we have to credit the defense with <img src="https://latex.codecogs.com/png.latex?+.8"> drops added, <em>who</em> exactly on the defense do we give that credit to? There are a couple of heuristics that might make sense. One option would be to just split the credit up evenly among the defense, but this would be a bad heuristic because some defenders will have more of an impact on a pass being caught than others, and thus deserve more credit. We might also give all of the credit to the nearest defender, but that would be unfair to players who are within half a yard of the play and are also affecting its outcome but would get no credit under this heuristic. Ultimately, we opted to use the models to engineer the credit each player deserves by seeing how the catch probabilities would change if we magically removed them from the field, which we believe to be a better heuristic than the previous ones described. To implement this heuristic, we remove one defender from our data and re-run the predictions to see how big the magnitude of the change in catch probability is. The bigger the magnitude difference, the more credit that player gets. Then, we calculate the credit each defender gets with <img src="https://latex.codecogs.com/png.latex?credit_%7Bi%7D%20=%20%5Cfrac%7Bmin(d_%7Bi%7D,%200)%7D%7B%5Csum_%7Bi%7D%20min(d_%7Bi%7D,%200)%7D"> where <img src="https://latex.codecogs.com/png.latex?d_%7Bi%7D"> is the catch probability without that player on the field minus the catch probability with him on the field. In other words, if one player gets <img src="https://latex.codecogs.com/png.latex?75%5C%25"> of the credit for a play and the play is worth <img src="https://latex.codecogs.com/png.latex?+.8"> drops added, then that player gets <img src="https://latex.codecogs.com/png.latex?.8%20%5Ccdot%20.75%20=%20+.6"> drops of credit, and the remaining <img src="https://latex.codecogs.com/png.latex?+.2"> drops are divvied up amongst the other defenders in the same fashion.</p>
</section>
<section id="target-probability" class="level2">
<h2 class="anchored" data-anchor-id="target-probability">Target Probability</h2>
<p>Our target model is based on comparing the probabilities that a receiver is targeted before the play begins and when the ball is thrown with the actual receiver targeted. We can use these probabilities to make estimates of how well the defender is covering (are receivers less likely to be thrown the ball because of the pre-throw work of a defensive back?) and how much respect they get from opposing offenses (do quarterbacks tend to make different decisions at throw time because of the defensive back?).</p>
<p>To determine the probability of a receiver being targeted before the play, we chose to take a naive approach. Each receiver on the field is assigned a “target rate” of <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7Btargets%7D%7B%5Csqrt%7Bplays%7D%7D">, which is then adjusted for the other receivers on the field and used as the only feature for a logit model. The idea of this rate was to construct a statistic that rewarded receivers for showing high target rates over a large sample but also gave receivers who play more often more credit.</p>
<p>The model for target probability at the time of throw was a tree booster similar to the two catch probability models. This model uses positional data, comparing the receiver position to the QB and the three closest defenders along with a variety of situational factors such as the distance to the first down line, time left, weather conditions, and how open that receiver is relative to others on the play to determine how likely that receiver is to be targeted.</p>
<p>The pre-snap model, which by design only considers the players on the field for the offense, performs relatively well for the lack of information with an AUC of <img src="https://latex.codecogs.com/png.latex?.59"> and is well-calibrated on a held-out dataset. The pre-throw model performs much better given the extra information, with <img src="https://latex.codecogs.com/png.latex?89%5C%25"> recall, <img src="https://latex.codecogs.com/png.latex?94%5C%25"> precision, and <img src="https://latex.codecogs.com/png.latex?.94"> AUC. Calibration plots of the models on held-out data are below.</p>
<p><img src="https://www.matthewrkaye.com/posts/2021-01-07-our-2021-big-data-bowl-submission/https:/raw.githubusercontent.com/hjmbigdatabowl/bdb2021/main/inst/plots/target_calplot_calibrated.png" class="img-fluid" alt="cal_plot_target_model_throw"> <img src="https://www.matthewrkaye.com/posts/2021-01-07-our-2021-big-data-bowl-submission/https:/raw.githubusercontent.com/hjmbigdatabowl/bdb2021/main/inst/plots/target_calplot_pre_snap.png" class="img-fluid" alt="cal_plot_target_model_presnap"></p>
<p>We can estimate how a defensive back is impacting the decisions made by the quarterback through two effects. The first, comparing the target probability before the play to the target probability at the time of the throw is meant to estimate how well the receiver is covered on the play. For example, consider a receiver with a target probability of <img src="https://latex.codecogs.com/png.latex?20%5C%25"> before the snap who ends up open enough to get a target probability of <img src="https://latex.codecogs.com/png.latex?50%5C%25"> when the ball is thrown. This difference is attributed to the closest defensive back who would be credited with <img src="https://latex.codecogs.com/png.latex?-0.3"> coverage targets. If on the same play another receiver had a pre-snap target probability <img src="https://latex.codecogs.com/png.latex?30%5C%25"> but a target probability of <img src="https://latex.codecogs.com/png.latex?0%5C%25"> at throw time, the closest defensive back would be credited with <img src="https://latex.codecogs.com/png.latex?+0.3"> coverage targets. The other effect attempts to measure how the quarterback is deterred from throwing when that particular defensive back is in the area of the receiver by comparing the probability of a target to the actual result. So if a certain receiver has a target probability of <img src="https://latex.codecogs.com/png.latex?60%5C%25"> at the time of the throw and isn’t targeted, the closest defender is credited with <img src="https://latex.codecogs.com/png.latex?+0.6"> deterrence targets.</p>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<p>Having produced these four models that gave us estimates of the influence of the defensive backs on a given play, we can accumulate the results over an entire season to produce an estimate of individual skill across the dimensions described by the models. As there is no straightforward way to measure the relative value of these skills, we chose to combine the individual skill percentiles for each defender as a measure of their overall skill. With that as the estimate, these are our top 15 pass-defending defensive backs in 2018:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.matthewrkaye.com/posts/2021-01-07-our-2021-big-data-bowl-submission/https:/raw.githubusercontent.com/hjmbigdatabowl/bdb2021/main/inst/plots/final_leaderboard.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">leaderboard</figcaption><p></p>
</figure>
</div>
<p>A full leaderboard of these can be found <a href="https://bdb-2021.herokuapp.com/">on our Shiny app</a> in the <code>Overall Rankings</code> tab. To help display these results and a few other metrics (such as how difficult the defensive assignment was based on pre-snap target probability and actual separation from the receiver at throw time) we developed player cards for each qualifying defender. For example, this is our card for #1 defender Richard Sherman:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.matthewrkaye.com/posts/2021-01-07-our-2021-big-data-bowl-submission/https:/raw.githubusercontent.com/hjmbigdatabowl/bdb2021/main/inst/plots/sherman_card.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">sherman_card</figcaption><p></p>
</figure>
</div>
<p>These cards can also be found on our Shiny app under <code>Player Cards</code>.</p>
</section>
<section id="further-work" class="level2">
<h2 class="anchored" data-anchor-id="further-work">Further Work</h2>
<p>There are several things that we didn’t consider or that would be interesting extensions of this project. Two clear ones are interceptions added and fumbles added, as those are hugely impactful football plays that can swing the outcomes of games. We also only considered raw changes in aggregating the player stats (i.e.&nbsp;targets prevented and drops added), but using EPA added instead would certainly be a better metric, since not all drops are created equal. In addition, it is not clear that a drop added is worth the same as a target deterred – an assumption we made – and EPA would help solve this problem too. It would also be interesting to test how similar our metrics are between seasons to confirm that our metrics are measuring the stable skill of a defender.</p>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<p>All of our code is hosted in two Github repos: <a href="https://github.com/hjmbigdatabowl/bdb2021">hjmbigdatabowl/bdb2021</a>, which hosts our modeling code, and <a href="https://github.com/hjmbigdatabowl/bdb2021-shiny">hjmbigdatabowl/bdb2021-shiny</a>, which hosts the Shiny app.</p>
<p>There is extensive documentation for our code on our <a href="https://hjmbigdatabowl.github.io/bdb2021/reference/">pkgdown site</a>.</p>
<p>The Shiny app can be found <a href="https://bdb-2021.herokuapp.com/">here</a>, which lets you explore our models, results, and player ratings.</p>
</section>
<section id="thoughts" class="level2">
<h2 class="anchored" data-anchor-id="thoughts">Thoughts</h2>
<p>First, a disclaimer for everything that follows: I’m extremely proud of what we submitted, and the work that we did. We spent hundreds of hours working on this project over about three months, which is an enormous undertaking for four people with other full-time commitments. Especially in the final weeks, I was spending well over ten hours a week working on this project, and probably closer to fifteen or twenty. All of that said, in the grand scheme of things, the 300 hours or so collective hours that we spent conceiving of and working on this project is nowhere near the amount of time and effort that could be poured into a project that a data science team of four was working on full-time for three months. Given more time, I believe there are significant ways in which we could have improved our final product.</p>
<section id="strengths" class="level3">
<h3 class="anchored" data-anchor-id="strengths">Strengths</h3>
<ol type="1">
<li><strong>Communication and interpretability of the results.</strong> At the end of the day, when you work in a front office (as Hugh, John, and I know), you need coaches to believe what you’re telling them, and building a product that they can understand and explain is a major step in that direction. Overly complex or convoluted methodology will only get your work ignored, and I think that we did a particularly good job of building a product that is interpretable and useful.</li>
<li><strong>Building a model that evaluates something useful.</strong> At the end of the day, I’m happy with the statistics we chose to put forward. In my view, barring special events like fumbles forced, tackling, and interceptions (all valuable things that should be worked on further to expand this project), the way that we evaluate defensive back performance by looking at what we view as the four major components – deterring passes by reputation, deterring passes with good positioning and coverage, closing down receivers, and breaking up passes – are the four most important skills for defensive backs in the NFL.</li>
<li><strong>Divvying up credit in a clever way.</strong> I also think that the way we opted to divvy up the credit among the defenders in the two catch probability models was particularly clever, and not something that most teams would do. As we laid out in our submission, it doesn’t make sense to divvy credit evenly or give all credit to the nearest defender to the target, and I think that the approach that we took was both novel and easily defensible.</li>
</ol>
</section>
<section id="weaknesses-potential-improvements" class="level3">
<h3 class="anchored" data-anchor-id="weaknesses-potential-improvements">Weaknesses + Potential Improvements</h3>
<ol type="1">
<li>Clearly, weighing each of the four components of defense that we measured equally is the wrong way to go. A better strategy would be to try to correlate them with defensive EPA or a similar stat and use the correlation coefficients / R-Squared values / MSEs / etc. to weigh the four components based on how strongly they predict EPA. The problem, though, is that we don’t have a defensive EPA, which means we’d need to model it. In addition, it’s unclear how to model a <em>counterfactual</em>. What I mean by that is that for a statistic like deterrence, we need to measure the EPA caused by a defender <em>not</em> being thrown at, which is an inherently difficult thing to model. So difficult, in fact, that I believe that the first NFL team to come up with a good way of doing this will have a Moneyball-esque leg up against the competition until other teams catch up (Ravens analysts, I’m looking at you).</li>
<li>There are other aspects of defensive performance that we’re not measuring. Two important categories are turnovers generated and YAC prevented. Both of these are hugely valuable for preventing points, and both are models that we didn’t have time to build.</li>
<li>Stability testing. We’re probably interested in how stable our metrics are across seasons. For example, does Stephon Gilmore being a 96 overall this year predict his rating next year at all? Since we only have one season of data, the answer is that we don’t know. This type of stability testing would be useful for predicting future performance, though.</li>
</ol>
</section>
<section id="general-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="general-thoughts">General Thoughts</h3>
<p>Again, I’m proud of what we’ve done here. In particular, spot-checking some of the numbers has been fascinating. There’s often very little correlation between metrics, which seems good, and often the correlations can be negative. The way to think about this, as my teammate Hugh eloquently put it, is that we should think about the negative correlations as being similar to <img src="https://latex.codecogs.com/png.latex?ISO"> vs.&nbsp;<img src="https://latex.codecogs.com/png.latex?K%25"> in the MLB: A player who is fantastic in coverage and thus often deters throws necessarily will have fewer opportunities to break up passes, meaning he will see a lower score for closing, breakups, or both. We see this type of behavior with Gilmore, Peterson, Sherman, and more. It’s also been interesting to find that our models think the same corners are really good as the eye test does, which is an encouraging sign. Interestingly, though, some of our top-ranked defensive backs are players who don’t tend to make top lists, and some of our lowest-ranked ones (like Jason McCourty and Jalen Ramsey), do. This is reminiscent of the attitude changes about certain MLB players in the early 2010s as we began developing more advanced statistics to measure performance (i.e.&nbsp;Derek Jeter’s defense being terrible and Michael Bourn being sneakily good).</p>
<p>And with that, I’ve wrapped up my addendum to our submission. Feel free to reach out with any questions. My contact info is on my blog, my Github, my LinkedIn, etc. Thanks for reading!</p>


</section>
</section>

 ]]></description>
  <category>data science</category>
  <category>sports analytics</category>
  <guid>https://www.matthewrkaye.com/posts/2021-01-07-our-2021-big-data-bowl-submission/index.html</guid>
  <pubDate>Thu, 07 Jan 2021 05:00:00 GMT</pubDate>
  <media:content url="https://raw.githubusercontent.com/hjmbigdatabowl/bdb2021/main/inst/plots/calplot_a.png" medium="image" type="image/png"/>
</item>
</channel>
</rss>
